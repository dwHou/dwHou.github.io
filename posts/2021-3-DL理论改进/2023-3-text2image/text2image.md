#### :page_with_curl:GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis

CVPR2023 校友的



#### :page_with_curl:Scaling up GANs for Text-to-Image Synthesis

CVPR2023

##### 背景

> 在文生图领域，扩散模型似乎已经一统天下，让曾经也风头无两的 GAN 显得有些过时。但两相比较，GAN 依然存在不可磨灭的优势。这使得一些研究者在这一方向上持续努力，并取得了非常实用的成果。

扩散模型成为目前占据主导地位的范式。然而，扩散模型依赖于迭代推理，这是一把双刃剑，因为迭代方法可以实现具有简单目标的稳定训练，但推理过程需要高昂的计算成本。

相比于扩散模型，GAN 通过单个前向传递生成图像，因此本质上是更高效的，但由于训练过程的不稳定性，扩展 GAN 需要仔细调整网络架构和训练因素。因此，GAN 擅长对单个或多个对象类进行建模，但扩展到复杂数据集（更不用说现实世界）则极具挑战性。因此，超大型模型、数据和计算资源现在都专用于扩散模型和自回归模型。但作为一种高效的生成方法，许多研究者并没有完全放弃 GAN 方法。

现在，在一篇 CVPR 2023 论文 **Scaling up GANs for Text-to-Image Synthesis** 中，来自 POSTECH、卡耐基梅隆大学和 Adobe 研究院的研究者们联合探究了关于 GAN 的几个重要问题，包括：

- GAN 能否继续扩大规模并从大量资源中受益，GAN 遇到瓶颈了吗？
- 是什么阻止了 GAN 的进一步扩展，我们能否克服这些障碍？

该篇文章确定了几个关键问题，并提出了在增加模型容量的同时稳定训练的技术，提出GigaGAN。





我的评价：考虑落地速度，gigaGAN、GALIP