<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>æ·±åº¦å­¦ä¹ æ¡†æ¶</title>

        <link rel="stylesheet" href="../../fonts/Serif/cmun-serif.css" />
        <link rel="stylesheet" href="../../fonts/Serif-Slanted/cmun-serif-slanted.css" />

        <!--BOOTSTRAP-->
        <link href="../../bootstrap/css/bootstrap.min.css" rel="stylesheet">
        <!--mobile first-->
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <!--removed html from url but still is html-->
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

        <!--font awesome-->
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

        <!--fonts: allan & cardo-->
        <link href="http://fonts.googleapis.com/css?family=Droid+Serif" rel="stylesheet" type="text/css">
        <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        <link href="../../css/sticky-footer-navbar.css" rel="stylesheet">

        <link href="../../css/default.css" rel="stylesheet">

        <link href="../../comments/inlineDisqussions.css" rel="stylesheet">

        <!--Highlight-->
        <link href="../../highlight/styles/github.css" rel="stylesheet">

        <link href="../../favicon.ico" rel="shortcut icon" />

        <!--<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
        <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <style>
        .post{width:170px;min-height:175px;padding-left:5px;padding-right:5px;float:left;border-left:1px solid #CCC;background-color:white;}
        div a:first-of-type .post { border-left: none; }
        .post:hover {filter: brightness(90%);}
        .post h3{margin:5px;font-size:75%;text-align:center}
        .post h4{margin:0px;font-size:50%;text-align:center}
        .post img{margin:0px;padding:2px;margin-bottom:10px;width:100%;height:155px}
        </style>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-49811703-1', 'dwHou.github.io');
          ga('require', 'linkid', 'linkid.js');
          ga('require', 'displayfeatures');
          ga('send', 'pageview');

        </script>

    </head>

    <body>
        <div id="wrap">
            <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
                <div class="container">
                    <!--Toggle header for mobile-->
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand active" href="../../" style="font-size:20px;">De's blog</a>
                    </div>
                    <!--normal header-->
                    <div class="navbar-collapse collapse">
                        <ul class="nav navbar-nav navbar-right">
                            <li><a href="../../"><span class="glyphicon glyphicon-pencil"></span>  Blog</a></li>
                            <li><a href="../../about.html"><span class="glyphicon glyphicon-user"></span>  About</a></li>
                            <li><a href="../../contact.html"><span class="glyphicon glyphicon-envelope"></span>  Contact</a></li>
                            <li><a href="../../demo.html"><span class="glyphicon glyphicon-play"></span>  ALGO</a></li>
                        </ul>
                    </div><!--/.nav-collapse -->
                </div>
            </nav>


            <div id="content">
                <div class="container">
                    <div class="row">
                        <div class="col-md-8">
                            <h1>PyTorch</h1>
                            <div style="font-size: 170%;">æŒç»­æ›´æ–°</div>
                            <br>
                            <div class="info">
    <p style="font-family:CMSS; font-size:120%">Posted on Feb.19, 2020</p>

    <!--
        by dwHou
    -->
</div>
</br>


  <style>
    ul li {
      margin-top: 12px;
    }

    .tight-list li {
      margin-top: 6px;
    }
  </style>


  <h2>Pytorchå¸¸ç”¨ä»£ç æ®µ</h2>
  <ul>

  <li><a href="./PyTorchå¸¸ç”¨ä»£ç æ®µ.html"> ğŸ““Cookbook </a></li>
    
  </ul>


  <h2>æ¡†æ¶ä½¿ç”¨ç»éªŒ</h2>
  <ul>

  </ul>

  <h2>æ·±åº¦å­¦ä¹ å®éªŒç®¡ç†</h2>
  <style>
    .hovertext:hover {font-weight: lighter; color: #58ACFA; }
  </style>
  ä»¥ä¸€ä¸ªå¼€æº<a class="hovertext" href="https://github.com/L1aoXingyu/Deep-Learning-Project-Template">codebase</a>ä¸ºä¾‹ï¼Œ
  å¦‚æœé•¿æœŸç»´æŠ¤ä¸€ä¸ªæ·±åº¦å­¦ä¹ é¡¹ç›®ï¼Œä»£ç çš„ç»„ç»‡å°±æ¯”è¾ƒé‡è¦äº†ã€‚å¦‚ä½•è®¾è®¡ä¸€ä¸ªç®€å•è€Œå¯æ‰©å±•çš„ç»“æ„æ˜¯éå¸¸é‡è¦çš„ã€‚
  è¿™å°±éœ€è¦ç”¨åˆ°è½¯ä»¶å·¥ç¨‹ä¸­çš„OOPè®¾è®¡ã€‚è®©æˆ‘ä»¬é«˜æ•ˆã€æ ‡å‡†åŒ–åœ°ç®¡ç†æ·±åº¦å­¦ä¹ å®éªŒã€‚
  
  <ul>
      <style>.hovertext:hover {font-weight: bold; color: #58ACFA; }</style>
      <li><b><a href="./å®éªŒç®¡ç†.html" class="hovertext">è·³è½¬</a></b></li>
      <li>ç†Ÿæ‚‰å·¥å…·</li>
      <li>å‚æ•°ç®¡ç†</li>
      <li>æ—¥å¿—ç®¡ç†</li>
  </ul>
  

  <h2>é‡åˆ°çš„å‘/bug</h2>
  <ul>
      <li>in-placeæ“ä½œ</li>
      in-place operationåœ¨pytorchä¸­æ˜¯æŒ‡æ”¹å˜ä¸€ä¸ªtensorçš„å€¼çš„æ—¶å€™ï¼Œä¸ç»è¿‡å¤åˆ¶æ“ä½œï¼Œè€Œæ˜¯ç›´æ¥åœ¨åŸæ¥çš„å†…å­˜ä¸Šæ”¹å˜å®ƒçš„å€¼ã€‚å¯ä»¥æŠŠå®ƒæˆä¸ºåŸåœ°æ“ä½œç¬¦ã€‚
      åœ¨pytorchä¸­ç»å¸¸åŠ åç¼€â€œ_â€æ¥ä»£è¡¨åŸåœ°in-place operationï¼Œæ¯”å¦‚è¯´.add_() æˆ–è€….scatter()ã€‚pythoné‡Œé¢çš„+=ï¼Œ*=ä¹Ÿæ˜¯in-place operationã€‚
      PyTorchæ—§ç‰ˆæœ¬æœ‰æç¤ºï¼šé™¤éæ‚¨åœ¨å†…å­˜å‹åŠ›å¾ˆå¤§çš„æƒ…å†µä¸‹ï¼Œå¦åˆ™æ‚¨å¯èƒ½æ°¸è¿œä¸éœ€è¦ä½¿ç”¨å®ƒä»¬ã€‚
      å½“æ—¶çš„åŸå› æ˜¯ï¼‘ï¼è¦†ç›–æ¢¯åº¦è®¡ç®—æ‰€éœ€çš„å€¼ã€‚ï¼’ï¼æ¯ä¸ªin-placeæ“ä½œå®é™…ä¸Šéœ€è¦å®ç°é‡å†™è®¡ç®—å›¾ã€‚
      <pre>
          å·ç§¯è¿™äº›æ“ä½œä¸æ˜¯in-placeï¼Œ
          reluå¯é€‰in-placeï¼Œ
          -=,+=è¿™ç±»æ˜¯in-placeï¼Œ
          CAINå®ç°çš„æ”¹ç‰ˆçš„meanshiftâ€”â€”sub_mean()å°±ä¹Ÿæ˜¯in-placeçš„ã€‚
          å› ä¸ºä½ è¿›å…¥ç½‘ç»œå°±è¿›è¡Œäº†åŸåœ°æ“ä½œï¼Œæ‰€ä»¥prediction = model(input)ä¼šæ”¹åŠ¨åˆ°input.
          è§£å†³æ–¹æ¡ˆå°±æ˜¯ï¼Œè¿›å…¥ç½‘ç»œå
          foward(x):
                x = x.clone()
          RCANã€EDSRè¿™äº›DIV2kæ•°æ®é›†ä¸Šçš„Meanshiftæ˜¯ç”¨å·ç§¯æ–¹å¼å®ç°çš„ï¼Œå°±ä¸å­˜åœ¨è¿™ä¸ªé—®é¢˜ã€‚

          <font color="red">æ€»ç»“:</font> ä¸æƒ³å—åˆ°in-placeå½±å“çš„å˜é‡ï¼Œå¯ä»¥æ‹·è´x.copy()ï¼Œæˆ–è€…å¦‚æœæ˜¯å¼ é‡å¯ä»¥x.clone()ã€‚
      </pre>

      <li>æ£€æµ‹inplaceå¼‚å¸¸</li>
      <pre>
          # detect inplace-error
          torch.autograd.set_detect_anomaly(True)
      </pre>

      <li>åˆå§‹åŒ–</li>
      <pre>PyTorch Moduleè‡ªå¸¦çš„é»˜è®¤åˆå§‹åŒ–æ–¹æ³•å¾€å¾€æ›´å¯é ã€‚</pre>
      <li>æ•°æ®é›†è¾“å…¥é—®é¢˜</li>
      <pre>æŠŠè®­ç»ƒé›†dataloaderçš„shuffleå…³æ‰ï¼Œæº¯æºæ‰¾åˆ°æ•°æ®é›†å¯¹åº”å…ƒç´ ã€‚ä¾‹å¦‚ä¼˜é…·è¶…åˆ†æ•°æ®é›†å°±æœ‰2048x1152åˆ†è¾¨ç‡çš„è§†é¢‘ã€‚
           è¦è®°å¾—æ•°æ®é›†æ˜¯æœ‰shuffleçš„ï¼Œåœ¨å¤„ç†æ•°æ®é€»è¾‘æ—¶ä¸€å®šè¦æ„è¯†åˆ°ã€‚
      </pre>
      <li>æ¨¡å‹éªŒè¯é›†æŒºå¥½çš„ï¼Œç»“æœæµ‹è¯•è‰²åã€å¤±çœŸç‰¹åˆ«å¥‡æ€ª</li>
      <pre>å¾ˆæœ‰å¯èƒ½å°±æ˜¯å¿˜äº†model.load_state_dict()ï¼Œæ˜¯æŒ‰é»˜è®¤åˆå§‹åŒ–è·‘çš„å›¾ç‰‡ã€‚psnrç›´æ¥ä¼šé™åˆ°åå‡ äºŒåã€‚</pre>
      <li>PyTorchæµ‹è¯•æ¨¡å‹æ‰§è¡Œè®¡ç®—è€—è´¹çš„æ—¶é—´</li>
      <pre>
          <font color="#D2B4DE">ä¸€èˆ¬æˆ‘ä»¬éƒ½ä¼šä½¿ç”¨è¿™ç§æ–¹å¼ä¸€æµ‹è¯•æ—¶é—´</font>

          # æ–¹å¼ä¸€:
          star = time.time()
          result = model(input)
          end = time.time()

          <font color="#D2B4DE">ä½†æ­£ç¡®çš„åº”è¯¥æ˜¯ä¸‹è¾¹è¿™ç§æ–¹å¼äºŒ</font>

          # æ–¹å¼äºŒ:
          torch.cuda.synchronize()
          start = time.time()
          result = model(input)
          torch.cuda.synchronize()
          end = time.time()

          <font color="#D2B4DE">ä¸ºä»€ä¹ˆè¿™æ ·å‘¢ï¼Ÿ
          åœ¨pytorché‡Œé¢ï¼Œç¨‹åºçš„æ‰§è¡Œéƒ½æ˜¯å¼‚æ­¥çš„ã€‚å¦‚æœé‡‡ç”¨ç¬¬ä¸€ç§æ–¹å¼ï¼Œæµ‹è¯•çš„æ—¶é—´ä¼šå¾ˆçŸ­ï¼Œå› ä¸ºæ‰§è¡Œå®Œend=time.time()ç¨‹åºå°±é€€å‡ºäº†ï¼Œåå°çš„cuä¹Ÿå› ä¸ºpythonçš„é€€å‡ºé€€å‡ºäº†ï¼›
              å¦‚æœé‡‡ç”¨ç¬¬äºŒç§æ–¹å¼ï¼Œä»£ç ä¼šåŒæ­¥cuçš„æ“ä½œï¼Œç­‰å¾…gpuä¸Šçš„æ“ä½œéƒ½å®Œæˆäº†å†ç»§ç»­è®¡ç®—end = time.time()</font>

          <font color="#D2B4DE">å¦‚æœå°†æ–¹å¼ä¸€ä»£ç æ”¹ä¸ºæ–¹å¼ä¸‰ï¼š</font>

          # æ–¹å¼ä¸‰:
          start = time.time()
          result = model(input)
          print(result) #æˆ– result.cpu()
          end = time.time()

          <font color="#D2B4DE">è¿™æ—¶å€™ä¼šå‘ç°æ–¹å¼ä¸‰å’Œæ–¹å¼äºŒçš„æ—¶é—´æ˜¯ç±»ä¼¼çš„ï¼Œå› ä¸ºæ–¹å¼ä¸‰ä¼šç­‰å¾…gpuä¸Šçš„ç»“æœæ‰§è¡Œå®Œä¼ ç»™printå‡½æ•°ï¼Œæ‰€ä»¥æ­¤æ—¶é—´å°±å’Œæ–¹å¼äºŒåŒæ­¥æ“ä½œçš„æ—¶é—´åŸºæœ¬ä¸Šæ˜¯ä¸€è‡´çš„äº†ã€‚
              å°†print(result)æ¢æˆresult.cpu()ä¹Ÿå¯ä»¥å¾—åˆ°ç›¸åŒçš„ç»“æœã€‚</font>


          <font color="#D2B4DE">æ¥è‡ªä½œè€…ï¼šå‡ æ—¶è§å¾—æ¸…æ¢¦ çš„ç®€ä¹¦ç¬”è®°</font>

      </pre>
      <li>torch.cuda.synchronize()</li>
        ç­‰å¾…å½“å‰è®¾å¤‡ä¸Šæ‰€æœ‰æµä¸­çš„æ‰€æœ‰æ ¸å¿ƒå®Œæˆã€‚ å¦‚æœä¸åŠ syn, forwardä¼šé©¬ä¸Šè¿”å›ã€‚
        ä½†åŠ ä¸Šsynåï¼Œcpuä¼šç­‰å¾…æ¨¡å‹å®é™…è¿è¡Œå®Œå†è·å–æ•°æ®.å®é™…ä½¿ç”¨æ—¶ï¼Œå¦‚æœä¸é€æ®µç»Ÿè®¡æ—¶é—´ï¼Œå¯ä»¥ä¸åŠ è¿™ä¸ªsync.
        <pre>

            #<font color="#D4E6F1"></font>
            <font color="#2E86C1">
            from contextlib import contextmanager

            @contextmanager
            def timer(self, name):
                start = torch.cuda.Event(enable_timing=True)
                end = torch.cuda.Event(enable_timing=True)

                start.record()
                yield
                end.record()

                torch.cuda.synchronize()
                print(f'[{name}] done in {start.elapsed_time(end):.3f} ms')

            with timer('GTX 1080 Ti 720p inference'):
                    out = model(input)
            </font>
            è¿™æ ·ç»“æœæ‰ä¸€è‡´çš„æƒ¹ã€‚
        </pre>
      <li>å¯¹æ¯”è¯•éªŒçš„ä¼˜åŒ–å™¨å’Œlræ›´æ–°ç­–ç•¥</li>
      <pre>
â‘ ä¸ä½¿ç”¨scheduler, Adam + ä¸€ä¸ªå¤§çš„epochè®­ä¸‹å»ã€‚è¿™æ ·æ¯”è¾ƒå…¬å¹³ã€‚
â‘¡ReduceLROnPlateauæœ‰ç‚¹è¿æ°”æˆåˆ†ï¼Œè¦ä¹ˆå°±åœ¨lossæ˜¯å¦ä¸‹é™ä¸Šåšã€‚å¦‚æœæ˜¯éªŒè¯é›†PSNRï¼Œé‚£æœ€å¥½å°†å®¹å¿åº¦è®¾å¾ˆå¤§ã€‚
â‘¢ä½™å¼¦é€€ç«ã€‚ç­–ç•¥ä¸€è‡´å°±æ˜¯å¯ä»¥çš„ã€‚
      </pre>

      <li>train ä¸ val çš„åŒºåˆ«</li>
      <pre>
          model.train() ï¼šå¯ç”¨ BatchNormalization å’Œ Dropout
          model.eval() ï¼šä¸å¯ç”¨ BatchNormalization å’Œ Dropout
          valæ—¶ä¼šåŠ ä¸Š with torch.no_grad()
      </pre>

      <li>model.val() çš„æ³¨æ„äº‹é¡¹</li>
      <pre>
é¦–å…ˆçœ‹çœ‹å®˜æ–¹<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html?highlight=batchnorm#torch.nn.BatchNorm2d">Doc</a>æ¥å£
<a href="https://discuss.pytorch.org/t/model-eval-gives-incorrect-loss-for-model-with-batchnorm-layers/7561/2">Model.eval() gives incorrect loss for model with batchnorm layers</a>
æœ‰äººè¯´set the track_running_stats=False for all batch norm layers in the model.
for child in model.children():
    for ii in range(len(child)):
        if type(child[ii])==nn.BatchNorm2d:
            child[ii].track_running_stats = False
æœ‰äººè¯´è¿™ä¼¼ä¹å°±æ˜¯å›åˆ°äº†ä¸ç”¨model.eval()ï¼Œuses the current batchâ€™s
mean and variance to do the normalizationï¼Œæˆ‘è®¤ä¸ºè¿™å°±ç›¸å½“äºmomentum=0ã€‚ä¸å—å†å²çš„å½±å“ã€‚
<b>è€Œå‡ºç°è¿™ä¸ªæƒ…å†µçš„åŸå› ï¼Œå°±æ˜¯æ•°æ®é›†ä¸é€‚åˆç”¨batchnormï¼Œæ¯”å¦‚å¤ªå¤šnoisyäº†(æˆ‘ä»»åŠ¡ç¡®å®å¦‚æ­¤)ï¼Œbatchsizeå¤ªå°äº†(DDPæ—¶ç¡®å®)ï¼Œåˆ†å¸ƒç›¸å·®å¤ªå¤§å•¦ï¼Œ
æ‰€ä»¥è¿™é‡Œè¦æŠŠmomentumè®¾å°ï¼Œè®¾ç½®ä¸º0ï¼Œå³track_running_stats = Falseã€‚</b>
ä½†ä¹Ÿæœ‰ä¸ªå®˜æ–¹äººå£«å»ºè®®è®¾å¤§çš„ï¼Œè¿™æ ·æ›´èƒ½è§„é¿å¼‚å¸¸å€¼(non-stationary)ï¼Œç»´æŒä¹‹å‰å­¦ä¹ åˆ°çš„ã€‚

ä¸ªäººè®¤ä¸ºè¦æ·±åˆ»ç†è§£ï¼Œçµæ´»åº”ç”¨ï¼Œå†æƒ³ä¸€æƒ³ã€‚
<b>
æ¥ï¼Œæˆ‘ä»¬ä»åŸç†è¯´èµ·ã€‚æœ¬æ¥BatchNormæ˜¯å›åˆ°æ­£å¤ªåˆ†å¸ƒï¼Œè¿™æ ·å¯¹è®­ç»ƒæœ‰è®¸å¤šå¸®åŠ©ã€‚
ä½†æ˜¯å‘¢ï¼Œæ€ä¹ˆå›åˆ°æ­£å¤ªåˆ†å¸ƒå‘¢ï¼Œä½ è¦çŸ¥é“ç¼©æ”¾weightå’Œå¹³ç§»é‡biasã€‚
ä»»ä½•æ¡†æ¶ä¸‹çš„ä»»ä½•å½¢å¼çš„Normalizationéƒ½æ˜¯å¦‚æ­¤ï¼Œè¿™ä¸ªç¼©æ”¾å’Œå¹³ç§»çš„å€¼æ˜¯å¯å­¦ä¹ ã€å¯è®­ç»ƒçš„å‚æ•°ã€‚
æˆ‘ä»¬é€šè¿‡è¿™ä¸¤ä¸ªå‚æ•°ï¼Œèƒ½æŠŠç‰¹å¾è½¬åˆ°'æ­£å¤ª'ä¸Šã€‚ä½†æ˜¯ï¼æˆ‘ä»¬ä¸å¯èƒ½ï¼Œä¹Ÿæ²¡æƒ³è¦å®Œå…¨ä¸¥æ ¼çš„æ­£å¤ªåˆ†å¸ƒã€‚
â‘ æ¥ï¼Œweightå’Œbiasæ˜¯æ ¹æ®ç»Ÿè®¡ç‰¹æ€§å­¦ä¹ æ¥çš„ï¼Œå¯¹äºç‰¹å®šçš„ç‰¹å¾å®ƒä¹Ÿè½¬ä¸åˆ°æ­£å¤ªã€‚
â‘¡æ¥ï¼Œè‹¥æ˜¯çœŸçš„å…¨ä¸ºæ­£å¤ªäº†ï¼Œè¿˜æœ‰å•¥åŒºåˆ†åº¦ï¼Œæ²¡æœ‰å¯ç”¨ä¿¡æ¯äº†ã€‚
æ‰€ä»¥æˆ‘ä»¬çš„å®é™…ç›®çš„ï¼Œåªæ˜¯æ§åˆ¶å‡å€¼å’Œæ–¹å·®çš„å¤§å°ã€‚è€Œä¸æ˜¯åˆ†è¦å®ƒä»¬ä¸¥æ ¼ç­‰äºå¤šå°‘ã€‚

ç„¶åmomentumå°çš„è¯ï¼Œå¯ä»¥è®©weightå’Œbiasçš„å¾—å‡ºå¤šæ ¹æ®å½“å‰çš„è¾“å…¥ï¼Œå°‘ç´¯è®¡å†å²çš„å½±å“ã€‚
æˆ‘è®¤ä¸ºè¿™æ ·æ˜¯é˜²æ­¢åœ¨å†å²ä¸Šçš„"è¿‡æ‹Ÿåˆ"ï¼Œå®åˆ™å†å²ä¿¡æ¯å¯¹æ›´å¥½æ¥è¿‘æ­£å¤ªå¸®åŠ©ä¸å¤§ã€‚é€‚åˆæˆ‘ä»¬åœ¨åˆ†å¸ƒç»å¸¸å˜åŒ–çš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚
track_running_stats=Falseä¹Ÿæ˜¯è¿™ä¸ªä½œç”¨ï¼Œåªåˆ©ç”¨å½“å‰batchçš„ç»Ÿè®¡ä¿¡æ¯ï¼Œæ²¡æœ‰å†å²bufferã€‚

è€Œmomentumå¤§çš„è¯ï¼Œåˆ™æ›´ä¾èµ–å†å²bufferé‡Œçš„ä¿¡æ¯ã€‚è¿™æ ·è¯´æ˜å†å²ä¿¡æ¯çš„ä½œç”¨æ˜¯æ¯”å½“å‰ç»Ÿè®¡ä¿¡æ¯å¸®åŠ©å¤§çš„ã€‚

ç»¼ä¸Šï¼Œå»é«˜æ–¯å™ªå£°è¿™æ ·çš„ã€high-levelè¿™æ ·çš„ï¼Œç‰¹å¾å…¶å®åˆ†å¸ƒå¾ˆæœ‰ç‰¹ç‚¹ï¼Œå˜åŒ–ä¸å¤§ã€‚æ˜¯é€‚åˆç”¨batchnormï¼Œå¹¶ä¸”momentumå¤§ä¸€ç‚¹ã€‚
è‡³äºå¯¹é½ã€å…‰æµè¿™æ ·çš„ï¼Œmomentumå°ä¸€ç‚¹ä¿é™©ã€‚è¶…åˆ†è¾¨ç‡ï¼Œä¸ç”¨batchnormæ›´å¥½ã€‚
ç”¨æˆ–è€…ä¸ç”¨éƒ½å¥½è¯´ï¼Œæœ€ä¸å¸Œæœ›çš„æ˜¯è®­ç»ƒæ—¶å…¶ä»–æ¨¡å—é…åˆbatchnorm"è¿‡æ‹Ÿåˆ"åˆ°æ­£å¤ªï¼Œä½†ä½ æ¨ç†æ—¶batchnormåˆæ•ˆæœä¸å¥½ï¼Œåˆ°ä¸äº†æ­£å¤ªã€‚

è‡³äºmodel.eval()å¯¹å…¶çš„å½±å“ï¼Œ
During training, this layer keeps a running estimate of its computed mean and variance.
The running sum is kept with a default momentum of 0.1.

During evaluation, this running mean/variance is used for normalization.
æ„æ€å°±æ˜¯eval()æ—¶ï¼Œæ‰æŠŠæ‰€æœ‰å†å²ä¿¡æ¯æ‹¿å‡ºæ¥ç”¨ã€‚è¿™äº›éƒ½æ˜¯è®­ç»ƒ(running)æ—¶æŒ‰momentumæ¥å­˜ç€çš„ã€‚
ä¸ºä»€ä¹ˆè¦å¼€å¯å®ƒå‘¢ï¼Œè®¤ä¸ºå†å²ä¿¡æ¯æœ‰å¸®åŠ©ã€‚
è¿™å«åš<font color="red">"è´å¡å°”æ ¡æ­£"</font>
I mean, why is it better to use model.eval and
take the running statistics and not rely on the current test image statistics?
é‚£ä¸ºä»€ä¹ˆä»¥ä¸ºæœ‰å¸®åŠ©çš„eval()è¿˜å¯¼è‡´æ€§èƒ½ä¸‹é™å‘¢ã€‚å°±æ˜¯å†å²ä¿¡æ¯å…¶å®èµ·äº†è´Ÿé¢å½±å“ã€‚
ä½†æœ‰æ—¶eval()æ˜¯æœ‰å¸®åŠ©çš„ï¼Œä¼šæå‡æ•ˆæœã€‚ä½ å¯ä»¥é€šè¿‡åŒæ ·çš„checkpointï¼Œæ¨ç†æ—¶æ”¹å˜track_running_statsæ¥åˆ¤æ–­ã€‚
æœ€å<font color="red">æ‹©ä¼˜</font>ã€‚
if you compute test stat, then you are basically â€œtrainâ€ on test set,
because stat in this case is a trained param.
You can do it, nobody says you canâ€™t, just that ppl would consider it â€œcheatingâ€
ä½†è¿˜æœ‰å¾ˆé‡è¦çš„ä¸€ç‚¹ï¼ä¸€å®šè¦æµ‹è¯•æ—¶å¼€ç€eval()ï¼Œä¸ç„¶ç›¸å½“äºæ•°æ®"æ³„éœ²"ã€‚æµ‹è¯•é›†åœ¨è®­ç»ƒæ—¶ç•™äº†ç—•è¿¹ã€‚
è¿™æ ·çš„æµ‹è¯•æ˜¯ä¸å…¬æ­£çš„ã€‚
è¿™æ˜¯ä¸ºä»€ä¹ˆç”¨eval()çš„åŸå› ã€‚å¯ä»¥é˜²æ­¢"åœ¨æµ‹è¯•é›†è¿‡æ‹Ÿåˆ"ã€‚è‡³äºç”¨å®ƒåè€Œæ€§èƒ½ä¸‹é™å°±æ˜¯ä¸Šé¢è¯´çš„å†å²ä¿¡æ¯åè€Œä¸å¥½ã€‚

ç»“è®ºï¼šæˆ‘ä»¬ä¸€å®šè¦æ¨ç†ç”¨eval()ã€‚è‡³äºmomentumã€track_running_statsåˆ°åº•æ€ä¹ˆç”¨ï¼Œå°±ä¸ä¸€è€Œè¶³äº†ï¼Œä¸æ˜¯åŸåˆ™é—®é¢˜ï¼Œ
æ€ä¹ˆæ•ˆæœå¥½æ€ä¹ˆæ¥ã€‚æˆ‘çš„ç»éªŒæ˜¯ï¼Œå†å²ä¿¡æ¯ä¸€èˆ¬æ˜¯æœ‰ç”¨çš„ã€‚ä¸€èˆ¬æ¥è¯´track_running_statså¼€ç€ä¼šæœ‰å¸®åŠ©ã€‚
å†å²ä¿¡æ¯ä»€ä¹ˆæƒ…å†µè¶Šæ¥è¶Šæ²¡ç”¨å‘¢ï¼Œç”šè‡³è´Ÿé¢ä½œç”¨å‘¢ï¼Œå°±æ˜¯åˆ†å¸ƒå˜åŒ–å¤§ã€batchsizeå°(ä¹Ÿä½¿å¾—åˆ†å¸ƒæ³¢åŠ¨å¤§)çš„æ—¶å€™ï¼Œ
å†å²ä¸å½“å‰çš„Gapå¤ªå¤§ï¼Œå°±ä¸å¥½äº†ã€‚
è‡³äºé‚£äº›eval()ä¹‹åæ€§èƒ½è¿˜ä¸‹é™çš„ï¼Œé¦–å…ˆå®ƒä»¬ä¸€å¼€å§‹æ•°æ®æ³„éœ²äº†ï¼Œä¸å€¼å¾—æå€¡ã€‚å…¶æ¬¡track_running_stats=Falseç½¢ï¼Œå†å²ä¿¡æ¯è´Ÿé¢å¸®åŠ©ã€‚
ç»ˆç©¶track_running_stats=True or Falseå¯¹æ¯”ä¾¿çŸ¥, æˆ–è€…momentum=0æ¥è¯•, <font color="red">æ‹©ä¼˜</font>ã€‚

æˆ‘è§‰å¾—æœ€å¥½å°±æ˜¯ï¼Œè®­ç»ƒå®Œæˆåï¼Œå†å¤§batchçš„åªforwardï¼Œä¸backwardï¼Œå†ä¿å­˜æ¨¡å‹ã€‚è®©å†å²ä¿¡æ¯å……åˆ†å‘æŒ¥ä½œç”¨ï¼ï¼ï¼
</b>

ä½†ä¹Ÿæœ‰äººè¯´è¿™å…¶å®ä¸æ˜¯ä¸å¯¹çš„ã€‚
<font color="red">æˆ‘çš„è§‚ç‚¹ï¼Œæˆ–è®¸è¿™å’Œä»»åŠ¡ä»¥åŠä½ çš„è®­ç»ƒbatchå¤§å°æœ‰å…³ï¼Œå¦‚æœä»»åŠ¡ä¸è®²ç©¶batchï¼Œ
è®­ç»ƒæ—¶batchåˆå°ï¼Œæœ¬æ¥å°±ä¸ç¨³å®šï¼Œæˆ–è®¸ä¸éœ€è¦åŠ model.eval()äº†ã€‚</font>

Batch Normalizationé‡Œæœ‰ä¸€ä¸ªmomentumå‚æ•°, è¯¥å‚æ•°ä½œç”¨äºmeanå’Œvarianceçš„è®¡ç®—ä¸Š,
è¿™é‡Œä¿ç•™äº†å†å²batché‡Œçš„meanå’Œvarianceå€¼,å³ moving_meanå’Œmoving_variance,
å€Ÿé‰´ä¼˜åŒ–ç®—æ³•é‡Œçš„momentumç®—æ³•å°†å†å²batché‡Œçš„meanå’Œvarianceçš„ä½œç”¨å»¶ç»­åˆ°å½“å‰batch.
ä¸€èˆ¬momentumçš„å€¼ä¸º0.9 , 0.99ç­‰. å¤šä¸ªbatchå, å³å¤šä¸ª0.9è¿ä¹˜å,æœ€æ—©çš„batchçš„å½±å“ä¼šå˜å¼±.

æ‰€ä»¥ä¹Ÿæœ‰å»ºè®®ï¼Œåœ¨é‡åˆ°non-stationary trainingæ—¶ï¼Œ<font color="red">æŠŠmomentumè®¾å°ä¸€äº›ã€‚</font>
def evaluate_batch(net, batch, output, shouldeval):
        if shouldeval:
            net.eval()
            net.bn1.train()
            # æˆ‘æ„Ÿè§‰è¿™æ›´è¦ç»ï¼Œä¸ä»…ä¸ç”¨eval()äº†ï¼Œè¿˜ä¸ç•™ä»»ä½•å†å²å½±å“ã€‚æ˜¯å¦çŸ«æ‰è¿‡æ­£äº†ï¼Œæˆ‘ä¸ç”¨evalå°±æ˜¯äº†ã€‚
            net.bn1.momentum = 0.0
        else:
            net.train()
...
        #before returning
        net.bn1.momentum = 0.1

ä¸‹é¢è¿™æ®µæ˜¯æˆ‘çœ‹åˆ°æœ€æ¸…æ™°ç›´æ¥ã€è®²æ˜ç™½åŸç†æœ¬è´¨çš„è§£é‡Šäº†ã€‚
ã€ŒThe high validation loss is due to the wrong estimates of the running stats.
Since you are feeding a constant tensor (batchone: mean=1, std=0) and a random tensor (batchtwo: mean~=0, std~=1), the running estimates will be shaky and wrong for both inputs.

During training the current batch stats will be used to compute the output, so that the model might converge.
However, during evaluation the batchnorm layer tries to normalize both inputs with skewed running estimates, which yields the high loss values.
Usually we assume that all inputs are from the same domain and thus have approx. the same statistics.

If you set track_running_stats=False in your BatchNorm layer, the batch statistics will also be used during evaluation, which will reduce the eval loss significantly.ã€


If you turn track_running_stats off (as suggested in the post) you will instead
use the mean and std of the batch in eval mode. This is flawed and incorrect usage,
since you will get an inference result which is based on the data in your batch.
æ‰€ä»¥æå‡ºè¿™ä¸ªè§‚ç‚¹çš„äººè®¤ä¸ºå°±ä¸è¦ç”¨batchnormäº†ï¼Œè€Œæ˜¯ç”¨groupnormã€‚

å¾ˆå¤šäººé‡åˆ°è¿™ä¸ªé—®é¢˜æ— è®¡å¯æ–½ï¼Œä¹Ÿéƒ½æåˆ°ä¸ç”¨model.eval()å°±æ²¡é—®é¢˜ã€‚
I tried:
ãƒ»change the momentum term in BatchNorm constructor to higher.
ãƒ»before you set model.eval() , run a few inputs through model (just forward pass, you dont need to backward). This will help stabilize the running_mean / running_std values.
ãƒ»increase Batchsize
Nothing helped. ä¸è¿‡è¿™äººå‘ç°è‡ªå·±æ˜¯åœ¨ä¸åŒåœ°æ–¹ç”¨äº†åŒæ ·çš„batchnorm.
In the end I saw I was indeed using the same BatchNorm layers in different parts of the network.
Once I changed that it worked again.

      </pre>

      <li> torch.nn ä¸ torch.nn.functional</li>
      <pre>

      </pre>

      <li>åŠ è½½æ¨¡å‹æ¥ç€è®­ç»ƒï¼ŒAdamåŠ¨é‡å¯¹é½</li>
      <pre>
å¦‚æœä½¿ç”¨äº†Adamï¼Œåº”è¯¥ä¿å­˜optimizer state dictï¼Œä»¥ä¾¿ç»§ç»­è®­ç»ƒæ—¶åŠ è½½å®ƒã€‚
      </pre>

      <li> Metricså¼‚å¸¸ </li>
      <pre>
å¦‚æœLPIPSä¸PSNRã€SSIMçš„å¾—åˆ†æ˜æ˜¾ä¸æˆæ­£æ¯”æ—¶ï¼ŒPSNRå¼‚å¸¸ä½çš„é‚£ç»„æ•°æ®è€ƒè™‘æ£€æŸ¥æ˜¯ä¸æ˜¯å¸§æ²¡å¯¹ä¸Šã€‚æœ‰æ¬¡åŒå­¦çŠ¯äº†ä¸ªå¥½ç©çš„bugï¼Œå°±æ˜¯æŠŠEDVRå¼„æˆäº†input(0,1,2,3,4)ï¼Œè¶…åˆ†3å·å¸§ã€‚
ç»“æœæµ‹è¯•æ—¶è‡ªç„¶éƒ½ä¼šç§»åŠ¨ä¸€æ ¼ã€‚
æ²¡å¯¹ä¸Šçš„è¯ï¼ŒPSNRè‚¯å®šä½ï¼Œä½†å¯¹äºLPIPSè¿™æ ·çš„æŒ‡æ ‡å½±å“åˆ™ä¸å¤§ã€‚
      </pre>

      <li>PyTorch1.6è®­ç»ƒä¿å­˜çš„æ¨¡å‹åœ¨1.4ä½ç‰ˆæœ¬æ— æ³•åŠ è½½</li>
      <pre>
åœ¨1.6:  torch.save(model_.state_dict(), 'model_best_bacc.pth.tar', _use_new_zipfile_serialization=False)
https://github.com/pytorch/pytorch/issues/48915
æ³¨ï¼š è¿™ç§æ–¹å¼è½¬æ¢è¿‡çš„æ¨¡å‹ï¼Œå­—å…¸å…³é”®è¯ä¼šç§»é™¤å¤šå¡çš„æ ‡è¯†'module'
      </pre>

      <li>æ¨¡å‹å’Œä¿å­˜ç‚¹ä¸åŒ¹é…</li>
      <pre>
      åœ¨æ’é™¤äº†GPU/CPUå’Œå•å¡å¤šå¡çš„é—®é¢˜ä¹‹åï¼Œæ€€ç–‘åˆ°æ˜¯ä»£ç å˜åŠ¨ã€‚
          state_dict = torch.load(arg.ckp)
          from collections import OrderedDict
          new_state_dict = OrderedDict()
          for k, v in state_dict.items():
              name = k[7:] # remove 'module'.
              new_state_dict[name] = v
          print(new_state_dict.keys())
      å°†ç»“æœè¾“å‡ºåˆ° > module.txtçœ‹ï¼Œå®½åº¦ç¼©å°åˆ°å•æ ï¼Œç„¶åé¡ºç€ç½‘ç»œå±‚æ’æŸ¥æ˜¯å“ªå„¿çš„ä»£ç æ²¡å¯¹ä¸Šã€‚
      æˆ–
      for k in state_dict.keys():
        print(k)

      def print_network(net):
        num_params = 0
        for param in net.parameters():
            num_params += param.numel()
        print(net)
        print('Total number of parameters: %d' % num_params)
      </pre>

      <li>å±‚å±‚æ£€æŸ¥shapeå˜åŒ–</li>
      <pre>
          image = torch.zeros((1, 3, 64, 64))
          out = image
          for name, op in resnet18.items():
            out = op(out)
            print(name, out.shape)
          ä¸è¿‡è¿™éœ€è¦å®šä¹‰å’Œfowardå‡ºç°çš„å…ˆåé¡ºåºä¸€è‡´ã€‚
      </pre>

      <li>æ˜¾å­˜ä¸å¤Ÿç”¨ï¼Œä¸æ»¡è¶³å¤§patch & åˆé€‚çš„batch size</li>
      <pre>
          æ¢¯åº¦ç´¯åŠ 
          for i,(features,target) in enumerate(train_loader):
            outputs = model(images)  # å‰å‘ä¼ æ’­
            loss = criterion(outputs,target)  # è®¡ç®—æŸå¤±
            loss = loss/accumulation_steps   # å¯é€‰ï¼Œå¦‚æœæŸå¤±è¦åœ¨è®­ç»ƒæ ·æœ¬ä¸Šå–å¹³å‡

            loss.backward()  # è®¡ç®—æ¢¯åº¦
            if((i+1)%accumulation_steps)==0:
                optimizer.step()        # åå‘ä¼ æ’­ï¼Œæ›´æ–°ç½‘ç»œå‚æ•°
                optimizer.zero_grad()   # æ¸…ç©ºæ¢¯åº¦

          ä¸è¿‡bnå±‚ä¼šå—åˆ°ç‚¹å½±å“ï¼Œå¯é€šè¿‡è°ƒå°momentumå‚æ•°è§£å†³ã€‚
          https://www.zhihu.com/question/303070254
      </pre>

  </ul>



<!-- åŠ è½½å‡ºè¯„è®ºï¼Œæ˜¯ä½¿ç”¨Disqusçš„è®ºå›çŸ­åï¼ˆshortnameï¼‰
A shortname is the unique identifier assigned to a Disqus site. 

https://segmentfault.com/a/1190000005773009
https://help.disqus.com/en/articles/1717111-what-s-a-shortname
https://blog.csdn.net/weixin_34327761/article/details/89630337
   -->

<div id="disqus_thread"></div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../comments/inlineDisqussions.js"></script>
<script src="../../js/disqus.js"></script>

                        </div>
                        <div class="col-md-4"></div>
                    </div>
                </div>
            </div>


            <div id="footer">
                <div class="container">
                    Built by <a href="https://github.com/oinkina">Oinkina</a> with
                    <a href="http://jaspervdj.be/hakyll">Hakyll</a>
                    using <a href="http://getbootstrap.com/">Bootstrap</a>,
                    <a href="http://www.mathjax.org/">MathJax</a>,
                    <a href="http://disqus.com/">Disqus</a>,
                    <a href="https://github.com/unconed/MathBox.js">MathBox.js</a>,
                    <a href="http://highlightjs.org/">Highlight.js</a>,
                    and <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>.
                </div>
            </div>
        </div>

    <!-- jQuery-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

    <script src="../../bootstrap/js/bootstrap.min.js"></script>

    <script src="../../highlight/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <script src="../../js/footnotes.js"></script>

    <script src="../../comments/inlineDisqussions.js"></script>

    <noscript>Enable JavaScript for footnotes, Disqus comments, and other cool stuff.</noscript>

    </body>

</html>
