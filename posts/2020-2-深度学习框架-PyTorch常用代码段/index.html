<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>æ·±åº¦å­¦ä¹ æ¡†æ¶</title>

        <link rel="stylesheet" href="../../fonts/Serif/cmun-serif.css" />
        <link rel="stylesheet" href="../../fonts/Serif-Slanted/cmun-serif-slanted.css" />

        <!--BOOTSTRAP-->
        <link href="../../bootstrap/css/bootstrap.min.css" rel="stylesheet">
        <!--mobile first-->
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <!--removed html from url but still is html-->
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

        <!--font awesome-->
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

        <!--fonts: allan & cardo-->
        <link href="http://fonts.googleapis.com/css?family=Droid+Serif" rel="stylesheet" type="text/css">
        <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        <link href="../../css/sticky-footer-navbar.css" rel="stylesheet">

        <link href="../../css/default.css" rel="stylesheet">

        <link href="../../comments/inlineDisqussions.css" rel="stylesheet">

        <!--Highlight-->
        <link href="../../highlight/styles/github.css" rel="stylesheet">

        <link href="../../favicon.ico" rel="shortcut icon" />

        <!--<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
        <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <style>
        .post{width:170px;min-height:175px;padding-left:5px;padding-right:5px;float:left;border-left:1px solid #CCC;background-color:white;}
        div a:first-of-type .post { border-left: none; }
        .post:hover {filter: brightness(90%);}
        .post h3{margin:5px;font-size:75%;text-align:center}
        .post h4{margin:0px;font-size:50%;text-align:center}
        .post img{margin:0px;padding:2px;margin-bottom:10px;width:100%;height:155px}
        </style>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-49811703-1', 'dwHou.github.io');
          ga('require', 'linkid', 'linkid.js');
          ga('require', 'displayfeatures');
          ga('send', 'pageview');

        </script>

    </head>

    <body>
        <div id="wrap">
            <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
                <div class="container">
                    <!--Toggle header for mobile-->
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand active" href="../../" style="font-size:20px;">De's blog</a>
                    </div>
                    <!--normal header-->
                    <div class="navbar-collapse collapse">
                        <ul class="nav navbar-nav navbar-right">
                            <li><a href="../../"><span class="glyphicon glyphicon-pencil"></span>  Blog</a></li>
                            <li><a href="../../about.html"><span class="glyphicon glyphicon-user"></span>  About</a></li>
                            <li><a href="../../contact.html"><span class="glyphicon glyphicon-envelope"></span>  Contact</a></li>
                            <li><a href="../../demo.html"><span class="glyphicon glyphicon-play"></span>  ALGO</a></li>
                        </ul>
                    </div><!--/.nav-collapse -->
                </div>
            </nav>


            <div id="content">
                <div class="container">
                    <div class="row">
                        <div class="col-md-8">
                            <h1>PyTorch</h1>
                            <div style="font-size: 170%;">æŒç»­æ›´æ–°</div>
                            <br>
                            <div class="info">
    <p style="font-family:CMSS; font-size:120%">Posted on Feb.19, 2020</p>

    <!--
        by dwHou
    -->
</div>
</br>


  <style>
    ul li {
      margin-top: 12px;
    }

    .tight-list li {
      margin-top: 6px;
    }
  </style>


  <h2>Pytorchå¸¸ç”¨ä»£ç æ®µ</h2>
  <ul>

  <li><a href="./PyTorchå¸¸ç”¨ä»£ç æ®µ.html"> ğŸ““Cookbook </a></li>

  </ul>


  <h2>æ¡†æ¶ä½¿ç”¨ç»éªŒ</h2>
  <ul>

  </ul>

  <h2>æ·±åº¦å­¦ä¹ å®éªŒç®¡ç†</h2>
  <style>
    .hovertext:hover {font-weight: lighter; color: #58ACFA; }
  </style>
  ä»¥ä¸€ä¸ªå¼€æº<a class="hovertext" href="https://github.com/L1aoXingyu/Deep-Learning-Project-Template">codebase</a>ä¸ºä¾‹ï¼Œ
  å¦‚æœé•¿æœŸç»´æŠ¤ä¸€ä¸ªæ·±åº¦å­¦ä¹ é¡¹ç›®ï¼Œä»£ç çš„ç»„ç»‡å°±æ¯”è¾ƒé‡è¦äº†ã€‚å¦‚ä½•è®¾è®¡ä¸€ä¸ªç®€å•è€Œå¯æ‰©å±•çš„ç»“æ„æ˜¯éå¸¸é‡è¦çš„ã€‚
  è¿™å°±éœ€è¦ç”¨åˆ°è½¯ä»¶å·¥ç¨‹ä¸­çš„OOPè®¾è®¡ã€‚è®©æˆ‘ä»¬é«˜æ•ˆã€æ ‡å‡†åŒ–åœ°ç®¡ç†æ·±åº¦å­¦ä¹ å®éªŒã€‚

  <ul>
      <style>.hovertext:hover {font-weight: bold; color: #58ACFA; }</style>
      <li><b><a href="./å®éªŒç®¡ç†.html" class="hovertext">è·³è½¬</a></b></li>
      <li>ç†Ÿæ‚‰å·¥å…·</li>
      <li>å‚æ•°ç®¡ç†</li>
      <li>æ—¥å¿—ç®¡ç†</li>
  </ul>


  <h2>é‡åˆ°çš„å‘/bug</h2>
  <ul>
      <li>in-placeæ“ä½œ</li>
      in-place operationåœ¨pytorchä¸­æ˜¯æŒ‡æ”¹å˜ä¸€ä¸ªtensorçš„å€¼çš„æ—¶å€™ï¼Œä¸ç»è¿‡å¤åˆ¶æ“ä½œï¼Œè€Œæ˜¯ç›´æ¥åœ¨åŸæ¥çš„å†…å­˜ä¸Šæ”¹å˜å®ƒçš„å€¼ã€‚å¯ä»¥æŠŠå®ƒæˆä¸ºåŸåœ°æ“ä½œç¬¦ã€‚
      åœ¨pytorchä¸­ç»å¸¸åŠ åç¼€â€œ_â€æ¥ä»£è¡¨åŸåœ°in-place operationï¼Œæ¯”å¦‚è¯´.add_() æˆ–è€….scatter()ã€‚pythoné‡Œé¢çš„+=ï¼Œ*=ä¹Ÿæ˜¯in-place operationã€‚
      PyTorchæ—§ç‰ˆæœ¬æœ‰æç¤ºï¼šé™¤éæ‚¨åœ¨å†…å­˜å‹åŠ›å¾ˆå¤§çš„æƒ…å†µä¸‹ï¼Œå¦åˆ™æ‚¨å¯èƒ½æ°¸è¿œä¸éœ€è¦ä½¿ç”¨å®ƒä»¬ã€‚
      å½“æ—¶çš„åŸå› æ˜¯ï¼‘ï¼è¦†ç›–æ¢¯åº¦è®¡ç®—æ‰€éœ€çš„å€¼ã€‚ï¼’ï¼æ¯ä¸ªin-placeæ“ä½œå®é™…ä¸Šéœ€è¦å®ç°é‡å†™è®¡ç®—å›¾ã€‚
      <pre>
          å·ç§¯è¿™äº›æ“ä½œä¸æ˜¯in-placeï¼Œ
          reluå¯é€‰in-placeï¼Œ
          -=,+=è¿™ç±»æ˜¯in-placeï¼Œ
          CAINå®ç°çš„æ”¹ç‰ˆçš„meanshiftâ€”â€”sub_mean()å°±ä¹Ÿæ˜¯in-placeçš„ã€‚
          å› ä¸ºä½ è¿›å…¥ç½‘ç»œå°±è¿›è¡Œäº†åŸåœ°æ“ä½œï¼Œæ‰€ä»¥prediction = model(input)ä¼šæ”¹åŠ¨åˆ°input.
          è§£å†³æ–¹æ¡ˆå°±æ˜¯ï¼Œè¿›å…¥ç½‘ç»œå
          foward(x):
                x = x.clone()
          RCANã€EDSRè¿™äº›DIV2kæ•°æ®é›†ä¸Šçš„Meanshiftæ˜¯ç”¨å·ç§¯æ–¹å¼å®ç°çš„ï¼Œå°±ä¸å­˜åœ¨è¿™ä¸ªé—®é¢˜ã€‚

          <font color="red">æ€»ç»“:</font> ä¸æƒ³å—åˆ°in-placeå½±å“çš„å˜é‡ï¼Œå¯ä»¥æ‹·è´x.copy()ï¼Œæˆ–è€…å¦‚æœæ˜¯å¼ é‡å¯ä»¥x.clone()ã€‚
      </pre>

      <li>æ£€æµ‹inplaceå¼‚å¸¸</li>
      <pre>
          # detect inplace-error
          torch.autograd.set_detect_anomaly(True)
      </pre>

      <li>åˆå§‹åŒ–</li>
      <pre>PyTorch Moduleè‡ªå¸¦çš„é»˜è®¤åˆå§‹åŒ–æ–¹æ³•å¾€å¾€æ›´å¯é ã€‚</pre>
      <li>æ•°æ®é›†è¾“å…¥é—®é¢˜</li>
      <pre>æŠŠè®­ç»ƒé›†dataloaderçš„shuffleå…³æ‰ï¼Œæº¯æºæ‰¾åˆ°æ•°æ®é›†å¯¹åº”å…ƒç´ ã€‚ä¾‹å¦‚ä¼˜é…·è¶…åˆ†æ•°æ®é›†å°±æœ‰2048x1152åˆ†è¾¨ç‡çš„è§†é¢‘ã€‚
           è¦è®°å¾—æ•°æ®é›†æ˜¯æœ‰shuffleçš„ï¼Œåœ¨å¤„ç†æ•°æ®é€»è¾‘æ—¶ä¸€å®šè¦æ„è¯†åˆ°ã€‚
      </pre>
      <li>æ¨¡å‹éªŒè¯é›†æŒºå¥½çš„ï¼Œç»“æœæµ‹è¯•è‰²åã€å¤±çœŸç‰¹åˆ«å¥‡æ€ª</li>
      <pre>å¾ˆæœ‰å¯èƒ½å°±æ˜¯å¿˜äº†model.load_state_dict()ï¼Œæ˜¯æŒ‰é»˜è®¤åˆå§‹åŒ–è·‘çš„å›¾ç‰‡ã€‚psnrç›´æ¥ä¼šé™åˆ°åå‡ äºŒåã€‚</pre>
      <li>PyTorchæµ‹è¯•æ¨¡å‹æ‰§è¡Œè®¡ç®—è€—è´¹çš„æ—¶é—´</li>
      <pre>
          <font color="#D2B4DE">ä¸€èˆ¬æˆ‘ä»¬éƒ½ä¼šä½¿ç”¨è¿™ç§æ–¹å¼ä¸€æµ‹è¯•æ—¶é—´</font>

          # æ–¹å¼ä¸€:
          star = time.time()
          result = model(input)
          end = time.time()

          <font color="#D2B4DE">ä½†æ­£ç¡®çš„åº”è¯¥æ˜¯ä¸‹è¾¹è¿™ç§æ–¹å¼äºŒ</font>

          # æ–¹å¼äºŒ:
          torch.cuda.synchronize()
          start = time.time()
          result = model(input)
          torch.cuda.synchronize()
          end = time.time()

          <font color="#D2B4DE">ä¸ºä»€ä¹ˆè¿™æ ·å‘¢ï¼Ÿ
          åœ¨pytorché‡Œé¢ï¼Œç¨‹åºçš„æ‰§è¡Œéƒ½æ˜¯å¼‚æ­¥çš„ã€‚å¦‚æœé‡‡ç”¨ç¬¬ä¸€ç§æ–¹å¼ï¼Œæµ‹è¯•çš„æ—¶é—´ä¼šå¾ˆçŸ­ï¼Œå› ä¸ºæ‰§è¡Œå®Œend=time.time()ç¨‹åºå°±é€€å‡ºäº†ï¼Œåå°çš„cuä¹Ÿå› ä¸ºpythonçš„é€€å‡ºé€€å‡ºäº†ï¼›
              å¦‚æœé‡‡ç”¨ç¬¬äºŒç§æ–¹å¼ï¼Œä»£ç ä¼šåŒæ­¥cuçš„æ“ä½œï¼Œç­‰å¾…gpuä¸Šçš„æ“ä½œéƒ½å®Œæˆäº†å†ç»§ç»­è®¡ç®—end = time.time()</font>

          <font color="#D2B4DE">å¦‚æœå°†æ–¹å¼ä¸€ä»£ç æ”¹ä¸ºæ–¹å¼ä¸‰ï¼š</font>

          # æ–¹å¼ä¸‰:
          start = time.time()
          result = model(input)
          print(result) #æˆ– result.cpu()
          end = time.time()

          <font color="#D2B4DE">è¿™æ—¶å€™ä¼šå‘ç°æ–¹å¼ä¸‰å’Œæ–¹å¼äºŒçš„æ—¶é—´æ˜¯ç±»ä¼¼çš„ï¼Œå› ä¸ºæ–¹å¼ä¸‰ä¼šç­‰å¾…gpuä¸Šçš„ç»“æœæ‰§è¡Œå®Œä¼ ç»™printå‡½æ•°ï¼Œæ‰€ä»¥æ­¤æ—¶é—´å°±å’Œæ–¹å¼äºŒåŒæ­¥æ“ä½œçš„æ—¶é—´åŸºæœ¬ä¸Šæ˜¯ä¸€è‡´çš„äº†ã€‚
              å°†print(result)æ¢æˆresult.cpu()ä¹Ÿå¯ä»¥å¾—åˆ°ç›¸åŒçš„ç»“æœã€‚</font>


          <font color="#D2B4DE">æ¥è‡ªä½œè€…ï¼šå‡ æ—¶è§å¾—æ¸…æ¢¦ çš„ç®€ä¹¦ç¬”è®°</font>

      </pre>
      <li>torch.cuda.synchronize()</li>
        ç­‰å¾…å½“å‰è®¾å¤‡ä¸Šæ‰€æœ‰æµä¸­çš„æ‰€æœ‰æ ¸å¿ƒå®Œæˆã€‚ å¦‚æœä¸åŠ syn, forwardä¼šé©¬ä¸Šè¿”å›ã€‚
        ä½†åŠ ä¸Šsynåï¼Œcpuä¼šç­‰å¾…æ¨¡å‹å®é™…è¿è¡Œå®Œå†è·å–æ•°æ®.å®é™…ä½¿ç”¨æ—¶ï¼Œå¦‚æœä¸é€æ®µç»Ÿè®¡æ—¶é—´ï¼Œå¯ä»¥ä¸åŠ è¿™ä¸ªsync.
        <pre>

            #<font color="#D4E6F1"></font>
            <font color="#2E86C1">
            from contextlib import contextmanager

            @contextmanager
            def timer(self, name):
                start = torch.cuda.Event(enable_timing=True)
                end = torch.cuda.Event(enable_timing=True)

                start.record()
                yield
                end.record()

                torch.cuda.synchronize()
                print(f'[{name}] done in {start.elapsed_time(end):.3f} ms')

            with timer('GTX 1080 Ti 720p inference'):
                    out = model(input)
            </font>
            è¿™æ ·ç»“æœæ‰ä¸€è‡´çš„æƒ¹ã€‚
        </pre>
      <li>å¯¹æ¯”è¯•éªŒçš„ä¼˜åŒ–å™¨å’Œlræ›´æ–°ç­–ç•¥</li>
      <pre>
â‘ ä¸ä½¿ç”¨scheduler, Adam + ä¸€ä¸ªå¤§çš„epochè®­ä¸‹å»ã€‚è¿™æ ·æ¯”è¾ƒå…¬å¹³ã€‚
â‘¡ReduceLROnPlateauæœ‰ç‚¹è¿æ°”æˆåˆ†ï¼Œè¦ä¹ˆå°±åœ¨lossæ˜¯å¦ä¸‹é™ä¸Šåšã€‚å¦‚æœæ˜¯éªŒè¯é›†PSNRï¼Œé‚£æœ€å¥½å°†å®¹å¿åº¦è®¾å¾ˆå¤§ã€‚
â‘¢ä½™å¼¦é€€ç«ã€‚ç­–ç•¥ä¸€è‡´å°±æ˜¯å¯ä»¥çš„ã€‚
      </pre>

      <li>train ä¸ val çš„åŒºåˆ«</li>
      <pre>
          model.train() ï¼šå¯ç”¨ BatchNormalization å’Œ Dropout
          model.eval() ï¼šä¸å¯ç”¨ BatchNormalization å’Œ Dropout
          valæ—¶ä¼šåŠ ä¸Š with torch.no_grad()
      </pre>

      <li>model.val() çš„æ³¨æ„äº‹é¡¹</li>
      <pre>
é¦–å…ˆçœ‹çœ‹å®˜æ–¹<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html?highlight=batchnorm#torch.nn.BatchNorm2d">Doc</a>æ¥å£
<a href="https://discuss.pytorch.org/t/model-eval-gives-incorrect-loss-for-model-with-batchnorm-layers/7561/2">Model.eval() gives incorrect loss for model with batchnorm layers</a>
æœ‰äººè¯´set the track_running_stats=False for all batch norm layers in the model.
for child in model.children():
    for ii in range(len(child)):
        if type(child[ii])==nn.BatchNorm2d:
            child[ii].track_running_stats = False
æœ‰äººè¯´è¿™ä¼¼ä¹å°±æ˜¯å›åˆ°äº†ä¸ç”¨model.eval()ï¼Œuses the current batchâ€™s
mean and variance to do the normalizationï¼Œæˆ‘è®¤ä¸ºè¿™å°±ç›¸å½“äºmomentum=0ã€‚ä¸å—å†å²çš„å½±å“ã€‚
<b>è€Œå‡ºç°è¿™ä¸ªæƒ…å†µçš„åŸå› ï¼Œå°±æ˜¯æ•°æ®é›†ä¸é€‚åˆç”¨batchnormï¼Œæ¯”å¦‚å¤ªå¤šnoisyäº†(æˆ‘ä»»åŠ¡ç¡®å®å¦‚æ­¤)ï¼Œbatchsizeå¤ªå°äº†(DDPæ—¶ç¡®å®)ï¼Œåˆ†å¸ƒç›¸å·®å¤ªå¤§å•¦ï¼Œ
æ‰€ä»¥è¿™é‡Œè¦æŠŠmomentumè®¾å°ï¼Œè®¾ç½®ä¸º0ï¼Œå³track_running_stats = Falseã€‚</b>
ä½†ä¹Ÿæœ‰ä¸ªå®˜æ–¹äººå£«å»ºè®®è®¾å¤§çš„ï¼Œè¿™æ ·æ›´èƒ½è§„é¿å¼‚å¸¸å€¼(non-stationary)ï¼Œç»´æŒä¹‹å‰å­¦ä¹ åˆ°çš„ã€‚

ä¸ªäººè®¤ä¸ºè¦æ·±åˆ»ç†è§£ï¼Œçµæ´»åº”ç”¨ï¼Œå†æƒ³ä¸€æƒ³ã€‚
<b>
æ¥ï¼Œæˆ‘ä»¬ä»åŸç†è¯´èµ·ã€‚æœ¬æ¥BatchNormæ˜¯å›åˆ°æ­£å¤ªåˆ†å¸ƒï¼Œè¿™æ ·å¯¹è®­ç»ƒæœ‰è®¸å¤šå¸®åŠ©ã€‚
ä½†æ˜¯å‘¢ï¼Œæ€ä¹ˆå›åˆ°æ­£å¤ªåˆ†å¸ƒå‘¢ï¼Œä½ è¦çŸ¥é“ç¼©æ”¾weightå’Œå¹³ç§»é‡biasã€‚
ä»»ä½•æ¡†æ¶ä¸‹çš„ä»»ä½•å½¢å¼çš„Normalizationéƒ½æ˜¯å¦‚æ­¤ï¼Œè¿™ä¸ªç¼©æ”¾å’Œå¹³ç§»çš„å€¼æ˜¯å¯å­¦ä¹ ã€å¯è®­ç»ƒçš„å‚æ•°ã€‚
æˆ‘ä»¬é€šè¿‡è¿™ä¸¤ä¸ªå‚æ•°ï¼Œèƒ½æŠŠç‰¹å¾è½¬åˆ°'æ­£å¤ª'ä¸Šã€‚ä½†æ˜¯ï¼æˆ‘ä»¬ä¸å¯èƒ½ï¼Œä¹Ÿæ²¡æƒ³è¦å®Œå…¨ä¸¥æ ¼çš„æ­£å¤ªåˆ†å¸ƒã€‚
â‘ æ¥ï¼Œweightå’Œbiasæ˜¯æ ¹æ®ç»Ÿè®¡ç‰¹æ€§å­¦ä¹ æ¥çš„ï¼Œå¯¹äºç‰¹å®šçš„ç‰¹å¾å®ƒä¹Ÿè½¬ä¸åˆ°æ­£å¤ªã€‚
â‘¡æ¥ï¼Œè‹¥æ˜¯çœŸçš„å…¨ä¸ºæ­£å¤ªäº†ï¼Œè¿˜æœ‰å•¥åŒºåˆ†åº¦ï¼Œæ²¡æœ‰å¯ç”¨ä¿¡æ¯äº†ã€‚
æ‰€ä»¥æˆ‘ä»¬çš„å®é™…ç›®çš„ï¼Œåªæ˜¯æ§åˆ¶å‡å€¼å’Œæ–¹å·®çš„å¤§å°ã€‚è€Œä¸æ˜¯åˆ†è¦å®ƒä»¬ä¸¥æ ¼ç­‰äºå¤šå°‘ã€‚

ç„¶åmomentumå°çš„è¯ï¼Œå¯ä»¥è®©weightå’Œbiasçš„å¾—å‡ºå¤šæ ¹æ®å½“å‰çš„è¾“å…¥ï¼Œå°‘ç´¯è®¡å†å²çš„å½±å“ã€‚
æˆ‘è®¤ä¸ºè¿™æ ·æ˜¯é˜²æ­¢åœ¨å†å²ä¸Šçš„"è¿‡æ‹Ÿåˆ"ï¼Œå®åˆ™å†å²ä¿¡æ¯å¯¹æ›´å¥½æ¥è¿‘æ­£å¤ªå¸®åŠ©ä¸å¤§ã€‚é€‚åˆæˆ‘ä»¬åœ¨åˆ†å¸ƒç»å¸¸å˜åŒ–çš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚
track_running_stats=Falseä¹Ÿæ˜¯è¿™ä¸ªä½œç”¨ï¼Œåªåˆ©ç”¨å½“å‰batchçš„ç»Ÿè®¡ä¿¡æ¯ï¼Œæ²¡æœ‰å†å²bufferã€‚

è€Œmomentumå¤§çš„è¯ï¼Œåˆ™æ›´ä¾èµ–å†å²bufferé‡Œçš„ä¿¡æ¯ã€‚è¿™æ ·è¯´æ˜å†å²ä¿¡æ¯çš„ä½œç”¨æ˜¯æ¯”å½“å‰ç»Ÿè®¡ä¿¡æ¯å¸®åŠ©å¤§çš„ã€‚

ç»¼ä¸Šï¼Œå»é«˜æ–¯å™ªå£°è¿™æ ·çš„ã€high-levelè¿™æ ·çš„ï¼Œç‰¹å¾å…¶å®åˆ†å¸ƒå¾ˆæœ‰ç‰¹ç‚¹ï¼Œå˜åŒ–ä¸å¤§ã€‚æ˜¯é€‚åˆç”¨batchnormï¼Œå¹¶ä¸”momentumå¤§ä¸€ç‚¹ã€‚
è‡³äºå¯¹é½ã€å…‰æµè¿™æ ·çš„ï¼Œmomentumå°ä¸€ç‚¹ä¿é™©ã€‚è¶…åˆ†è¾¨ç‡ï¼Œä¸ç”¨batchnormæ›´å¥½ã€‚
ç”¨æˆ–è€…ä¸ç”¨éƒ½å¥½è¯´ï¼Œæœ€ä¸å¸Œæœ›çš„æ˜¯è®­ç»ƒæ—¶å…¶ä»–æ¨¡å—é…åˆbatchnorm"è¿‡æ‹Ÿåˆ"åˆ°æ­£å¤ªï¼Œä½†ä½ æ¨ç†æ—¶batchnormåˆæ•ˆæœä¸å¥½ï¼Œåˆ°ä¸äº†æ­£å¤ªã€‚

è‡³äºmodel.eval()å¯¹å…¶çš„å½±å“ï¼Œ
During training, this layer keeps a running estimate of its computed mean and variance.
The running sum is kept with a default momentum of 0.1.

During evaluation, this running mean/variance is used for normalization.
æ„æ€å°±æ˜¯eval()æ—¶ï¼Œæ‰æŠŠæ‰€æœ‰å†å²ä¿¡æ¯æ‹¿å‡ºæ¥ç”¨ã€‚è¿™äº›éƒ½æ˜¯è®­ç»ƒ(running)æ—¶æŒ‰momentumæ¥å­˜ç€çš„ã€‚
ä¸ºä»€ä¹ˆè¦å¼€å¯å®ƒå‘¢ï¼Œè®¤ä¸ºå†å²ä¿¡æ¯æœ‰å¸®åŠ©ã€‚
è¿™å«åš<font color="red">"è´å¡å°”æ ¡æ­£"</font>
I mean, why is it better to use model.eval and
take the running statistics and not rely on the current test image statistics?
é‚£ä¸ºä»€ä¹ˆä»¥ä¸ºæœ‰å¸®åŠ©çš„eval()è¿˜å¯¼è‡´æ€§èƒ½ä¸‹é™å‘¢ã€‚å°±æ˜¯å†å²ä¿¡æ¯å…¶å®èµ·äº†è´Ÿé¢å½±å“ã€‚
ä½†æœ‰æ—¶eval()æ˜¯æœ‰å¸®åŠ©çš„ï¼Œä¼šæå‡æ•ˆæœã€‚ä½ å¯ä»¥é€šè¿‡åŒæ ·çš„checkpointï¼Œæ¨ç†æ—¶æ”¹å˜track_running_statsæ¥åˆ¤æ–­ã€‚
æœ€å<font color="red">æ‹©ä¼˜</font>ã€‚
if you compute test stat, then you are basically â€œtrainâ€ on test set,
because stat in this case is a trained param.
You can do it, nobody says you canâ€™t, just that ppl would consider it â€œcheatingâ€
ä½†è¿˜æœ‰å¾ˆé‡è¦çš„ä¸€ç‚¹ï¼ä¸€å®šè¦æµ‹è¯•æ—¶å¼€ç€eval()ï¼Œä¸ç„¶ç›¸å½“äºæ•°æ®"æ³„éœ²"ã€‚æµ‹è¯•é›†åœ¨è®­ç»ƒæ—¶ç•™äº†ç—•è¿¹ã€‚
è¿™æ ·çš„æµ‹è¯•æ˜¯ä¸å…¬æ­£çš„ã€‚
è¿™æ˜¯ä¸ºä»€ä¹ˆç”¨eval()çš„åŸå› ã€‚å¯ä»¥é˜²æ­¢"åœ¨æµ‹è¯•é›†è¿‡æ‹Ÿåˆ"ã€‚è‡³äºç”¨å®ƒåè€Œæ€§èƒ½ä¸‹é™å°±æ˜¯ä¸Šé¢è¯´çš„å†å²ä¿¡æ¯åè€Œä¸å¥½ã€‚

ç»“è®ºï¼šæˆ‘ä»¬ä¸€å®šè¦æ¨ç†ç”¨eval()ã€‚è‡³äºmomentumã€track_running_statsåˆ°åº•æ€ä¹ˆç”¨ï¼Œå°±ä¸ä¸€è€Œè¶³äº†ï¼Œä¸æ˜¯åŸåˆ™é—®é¢˜ï¼Œ
æ€ä¹ˆæ•ˆæœå¥½æ€ä¹ˆæ¥ã€‚æˆ‘çš„ç»éªŒæ˜¯ï¼Œå†å²ä¿¡æ¯ä¸€èˆ¬æ˜¯æœ‰ç”¨çš„ã€‚ä¸€èˆ¬æ¥è¯´track_running_statså¼€ç€ä¼šæœ‰å¸®åŠ©ã€‚
å†å²ä¿¡æ¯ä»€ä¹ˆæƒ…å†µè¶Šæ¥è¶Šæ²¡ç”¨å‘¢ï¼Œç”šè‡³è´Ÿé¢ä½œç”¨å‘¢ï¼Œå°±æ˜¯åˆ†å¸ƒå˜åŒ–å¤§ã€batchsizeå°(ä¹Ÿä½¿å¾—åˆ†å¸ƒæ³¢åŠ¨å¤§)çš„æ—¶å€™ï¼Œ
å†å²ä¸å½“å‰çš„Gapå¤ªå¤§ï¼Œå°±ä¸å¥½äº†ã€‚
è‡³äºé‚£äº›eval()ä¹‹åæ€§èƒ½è¿˜ä¸‹é™çš„ï¼Œé¦–å…ˆå®ƒä»¬ä¸€å¼€å§‹æ•°æ®æ³„éœ²äº†ï¼Œä¸å€¼å¾—æå€¡ã€‚å…¶æ¬¡track_running_stats=Falseç½¢ï¼Œå†å²ä¿¡æ¯è´Ÿé¢å¸®åŠ©ã€‚
ç»ˆç©¶track_running_stats=True or Falseå¯¹æ¯”ä¾¿çŸ¥, æˆ–è€…momentum=0æ¥è¯•, <font color="red">æ‹©ä¼˜</font>ã€‚

æˆ‘è§‰å¾—æœ€å¥½å°±æ˜¯ï¼Œè®­ç»ƒå®Œæˆåï¼Œå†å¤§batchçš„åªforwardï¼Œä¸backwardï¼Œå†ä¿å­˜æ¨¡å‹ã€‚è®©å†å²ä¿¡æ¯å……åˆ†å‘æŒ¥ä½œç”¨ï¼ï¼ï¼
</b>

ä½†ä¹Ÿæœ‰äººè¯´è¿™å…¶å®ä¸æ˜¯ä¸å¯¹çš„ã€‚
<font color="red">æˆ‘çš„è§‚ç‚¹ï¼Œæˆ–è®¸è¿™å’Œä»»åŠ¡ä»¥åŠä½ çš„è®­ç»ƒbatchå¤§å°æœ‰å…³ï¼Œå¦‚æœä»»åŠ¡ä¸è®²ç©¶batchï¼Œ
è®­ç»ƒæ—¶batchåˆå°ï¼Œæœ¬æ¥å°±ä¸ç¨³å®šï¼Œæˆ–è®¸ä¸éœ€è¦åŠ model.eval()äº†ã€‚</font>

Batch Normalizationé‡Œæœ‰ä¸€ä¸ªmomentumå‚æ•°, è¯¥å‚æ•°ä½œç”¨äºmeanå’Œvarianceçš„è®¡ç®—ä¸Š,
è¿™é‡Œä¿ç•™äº†å†å²batché‡Œçš„meanå’Œvarianceå€¼,å³ moving_meanå’Œmoving_variance,
å€Ÿé‰´ä¼˜åŒ–ç®—æ³•é‡Œçš„momentumç®—æ³•å°†å†å²batché‡Œçš„meanå’Œvarianceçš„ä½œç”¨å»¶ç»­åˆ°å½“å‰batch.
ä¸€èˆ¬momentumçš„å€¼ä¸º0.9 , 0.99ç­‰. å¤šä¸ªbatchå, å³å¤šä¸ª0.9è¿ä¹˜å,æœ€æ—©çš„batchçš„å½±å“ä¼šå˜å¼±.

æ‰€ä»¥ä¹Ÿæœ‰å»ºè®®ï¼Œåœ¨é‡åˆ°non-stationary trainingæ—¶ï¼Œ<font color="red">æŠŠmomentumè®¾å°ä¸€äº›ã€‚</font>
def evaluate_batch(net, batch, output, shouldeval):
        if shouldeval:
            net.eval()
            net.bn1.train()
            # æˆ‘æ„Ÿè§‰è¿™æ›´è¦ç»ï¼Œä¸ä»…ä¸ç”¨eval()äº†ï¼Œè¿˜ä¸ç•™ä»»ä½•å†å²å½±å“ã€‚æ˜¯å¦çŸ«æ‰è¿‡æ­£äº†ï¼Œæˆ‘ä¸ç”¨evalå°±æ˜¯äº†ã€‚
            net.bn1.momentum = 0.0
        else:
            net.train()
...
        #before returning
        net.bn1.momentum = 0.1

ä¸‹é¢è¿™æ®µæ˜¯æˆ‘çœ‹åˆ°æœ€æ¸…æ™°ç›´æ¥ã€è®²æ˜ç™½åŸç†æœ¬è´¨çš„è§£é‡Šäº†ã€‚
ã€ŒThe high validation loss is due to the wrong estimates of the running stats.
Since you are feeding a constant tensor (batchone: mean=1, std=0) and a random tensor (batchtwo: mean~=0, std~=1), the running estimates will be shaky and wrong for both inputs.

During training the current batch stats will be used to compute the output, so that the model might converge.
However, during evaluation the batchnorm layer tries to normalize both inputs with skewed running estimates, which yields the high loss values.
Usually we assume that all inputs are from the same domain and thus have approx. the same statistics.

If you set track_running_stats=False in your BatchNorm layer, the batch statistics will also be used during evaluation, which will reduce the eval loss significantly.ã€


If you turn track_running_stats off (as suggested in the post) you will instead
use the mean and std of the batch in eval mode. This is flawed and incorrect usage,
since you will get an inference result which is based on the data in your batch.
æ‰€ä»¥æå‡ºè¿™ä¸ªè§‚ç‚¹çš„äººè®¤ä¸ºå°±ä¸è¦ç”¨batchnormäº†ï¼Œè€Œæ˜¯ç”¨groupnormã€‚

å¾ˆå¤šäººé‡åˆ°è¿™ä¸ªé—®é¢˜æ— è®¡å¯æ–½ï¼Œä¹Ÿéƒ½æåˆ°ä¸ç”¨model.eval()å°±æ²¡é—®é¢˜ã€‚
I tried:
ãƒ»change the momentum term in BatchNorm constructor to higher.
ãƒ»before you set model.eval() , run a few inputs through model (just forward pass, you dont need to backward). This will help stabilize the running_mean / running_std values.
ãƒ»increase Batchsize
Nothing helped. ä¸è¿‡è¿™äººå‘ç°è‡ªå·±æ˜¯åœ¨ä¸åŒåœ°æ–¹ç”¨äº†åŒæ ·çš„batchnorm.
In the end I saw I was indeed using the same BatchNorm layers in different parts of the network.
Once I changed that it worked again.

      </pre>

      <li> torch.nn ä¸ torch.nn.functional</li>
      <pre>

      </pre>

      <li>åŠ è½½æ¨¡å‹æ¥ç€è®­ç»ƒï¼ŒAdamåŠ¨é‡å¯¹é½</li>
      <pre>
å¦‚æœä½¿ç”¨äº†Adamï¼Œåº”è¯¥ä¿å­˜optimizer state dictï¼Œä»¥ä¾¿ç»§ç»­è®­ç»ƒæ—¶åŠ è½½å®ƒã€‚
      </pre>

      <li> Metricså¼‚å¸¸ </li>
      <pre>
å¦‚æœLPIPSä¸PSNRã€SSIMçš„å¾—åˆ†æ˜æ˜¾ä¸æˆæ­£æ¯”æ—¶ï¼ŒPSNRå¼‚å¸¸ä½çš„é‚£ç»„æ•°æ®è€ƒè™‘æ£€æŸ¥æ˜¯ä¸æ˜¯å¸§æ²¡å¯¹ä¸Šã€‚æœ‰æ¬¡åŒå­¦çŠ¯äº†ä¸ªå¥½ç©çš„bugï¼Œå°±æ˜¯æŠŠEDVRå¼„æˆäº†input(0,1,2,3,4)ï¼Œè¶…åˆ†3å·å¸§ã€‚
ç»“æœæµ‹è¯•æ—¶è‡ªç„¶éƒ½ä¼šç§»åŠ¨ä¸€æ ¼ã€‚
æ²¡å¯¹ä¸Šçš„è¯ï¼ŒPSNRè‚¯å®šä½ï¼Œä½†å¯¹äºLPIPSè¿™æ ·çš„æŒ‡æ ‡å½±å“åˆ™ä¸å¤§ã€‚
      </pre>

      <li>PyTorch1.6è®­ç»ƒä¿å­˜çš„æ¨¡å‹åœ¨1.4ä½ç‰ˆæœ¬æ— æ³•åŠ è½½</li>
      <pre>
åœ¨1.6:  torch.save(model_.state_dict(), 'model_best_bacc.pth.tar', _use_new_zipfile_serialization=False)
https://github.com/pytorch/pytorch/issues/48915
æ³¨ï¼š è¿™ç§æ–¹å¼è½¬æ¢è¿‡çš„æ¨¡å‹ï¼Œå­—å…¸å…³é”®è¯ä¼šç§»é™¤å¤šå¡çš„æ ‡è¯†'module'
      </pre>

      <li>æ¨¡å‹å’Œä¿å­˜ç‚¹ä¸åŒ¹é…</li>
      <pre>
      åœ¨æ’é™¤äº†GPU/CPUå’Œå•å¡å¤šå¡çš„é—®é¢˜ä¹‹åï¼Œæ€€ç–‘åˆ°æ˜¯ä»£ç å˜åŠ¨ã€‚
          state_dict = torch.load(arg.ckp)
          from collections import OrderedDict
          new_state_dict = OrderedDict()
          for k, v in state_dict.items():
              name = k[7:] # remove 'module'.
              new_state_dict[name] = v
          print(new_state_dict.keys())
      å°†ç»“æœè¾“å‡ºåˆ° > module.txtçœ‹ï¼Œå®½åº¦ç¼©å°åˆ°å•æ ï¼Œç„¶åé¡ºç€ç½‘ç»œå±‚æ’æŸ¥æ˜¯å“ªå„¿çš„ä»£ç æ²¡å¯¹ä¸Šã€‚
      æˆ–
      for k in state_dict.keys():
        print(k)

      def print_network(net):
        num_params = 0
        for param in net.parameters():
            num_params += param.numel()
        print(net)
        print('Total number of parameters: %d' % num_params)
      </pre>

      <li>å±‚å±‚æ£€æŸ¥shapeå˜åŒ–</li>
      <pre>
          image = torch.zeros((1, 3, 64, 64))
          out = image
          for name, op in resnet18.items():
            out = op(out)
            print(name, out.shape)
          ä¸è¿‡è¿™éœ€è¦å®šä¹‰å’Œfowardå‡ºç°çš„å…ˆåé¡ºåºä¸€è‡´ã€‚
      </pre>

      <li>æ˜¾å­˜ä¸å¤Ÿç”¨ï¼Œä¸æ»¡è¶³å¤§patch & åˆé€‚çš„batch size</li>
      <pre>
          æ¢¯åº¦ç´¯åŠ 
          for i,(features,target) in enumerate(train_loader):
              outputs = model(images)  # å‰å‘ä¼ æ’­
              loss = criterion(outputs,target)  # è®¡ç®—æŸå¤±
              loss = loss/accumulation_steps   # å¯é€‰ï¼Œå¦‚æœæŸå¤±è¦åœ¨è®­ç»ƒæ ·æœ¬ä¸Šå–å¹³å‡

              loss.backward()  # è®¡ç®—æ¢¯åº¦
              if((i+1)%accumulation_steps)==0:
                  optimizer.step()        # åå‘ä¼ æ’­ï¼Œæ›´æ–°ç½‘ç»œå‚æ•°
                  optimizer.zero_grad()   # æ¸…ç©ºæ¢¯åº¦

          ä¸è¿‡bnå±‚ä¼šå—åˆ°ç‚¹å½±å“ï¼Œå¯é€šè¿‡è°ƒå°momentumå‚æ•°è§£å†³ã€‚
          https://www.zhihu.com/question/303070254
      </pre>

      <pre>
          DDPæ¡†æ¶ä¸‹çš„æ¢¯åº¦ç´¯åŠ 
          from contextlib import nullcontext

          if local_rank != -1:
              model = DDP(model)

          optimizer.zero_grad()
          for i, (data, label) in enumerate(dataloader):
              my_context = model.no_sync if local_rank != -1 and i % accumulation_steps != 0 else nullcontext
              with my_context():
                  prediction = model(data)
                  loss = loss_fn(prediction, label) / accumulation_steps
                  loss.backward()
              if i % accumulation_steps == 0:
                  optimizer.step()
                  optimizer.zero_grad()
          å‚è€ƒï¼š
          https://zhuanlan.zhihu.com/p/250471767
      </pre>

      <li>GANè®­ç»ƒæ³¨æ„äº‹é¡¹</li>
      <pre>
        åˆ¤åˆ«å™¨éƒ¨åˆ†å°½é‡ä¸è¦å¤åˆ¶ç²˜è´´ç”Ÿæˆå™¨çš„ä»£ç ã€‚å› ä¸ºç”Ÿæˆå™¨å†™é”™å®¹æ˜“åœ¨è¿è¡Œæ—¶æŠ¥å‡ºï¼Œä½†åˆ¤åˆ«å™¨å¤åˆ¶ç²˜è´´å¯¼è‡´çš„é”™è¯¯å°±å¾ˆéšè”½ã€‚
        æ¯”å¦‚ï¼š
        optimizerD = torch.optim.Adam(model.parameters(), lr=5e-5), D.parameters()å°±è¯¯å†™ä¸ºmodel.parameters()ã€‚
      </pre>

      <li>Python, NumPy, Pytorchä¸­çš„å¤šè¿›ç¨‹ä¸­ æ¯ä¸ªè¿›ç¨‹çš„éšæœºåŒ–ç§å­ è¯¯åŒº</li>
      <pre>
        random.random(), numpy.random(), torch.random()
        <a href="https://blog.csdn.net/xiaojiajia007/article/details/87881231">å‚è€ƒ1</a>
        <a href="https://zhuanlan.zhihu.com/p/523239005">å‚è€ƒ2</a>
        PyTorch >= 1.9 å®˜æ–¹<a href="https://github.com/pytorch/pytorch/commit/aec83ff45ebd2cb3d4890cc97bffb1f367386392">ä¿®å¤</a>è¯¥é—®é¢˜
      </pre>

      <li>torch.roundçš„ä¸Šä¸‹å–æ•´è§„åˆ™</li>
      <pre>
        å’ŒOpenGLè¡¨ç°ä¸€æ ·ï¼šx.5ï¼Œxæ˜¯å¥‡æ•°çš„è¯æ˜¯å‘ä¸Šå–æ•´ï¼Œxæ˜¯å¶æ•°å‘ä¸‹
        https://github.com/Microsoft/DirectXShaderCompiler/issues/1671
      </pre>

      <li>å¤æ‚ç½‘ç»œç»“æ„çš„æ–‡ä»¶ï¼Œæ·»åŠ ç³»ç»Ÿç¯å¢ƒå˜é‡</li>
      <pre>
        ç›®çš„ï¼šé˜²æ­¢å‡ºç° ModuleNotFound é”™è¯¯
        sys.pathæ˜¯ä¸€ä¸ªåˆ—è¡¨ list ,å®ƒé‡Œé¢åŒ…å«äº†å·²ç»æ·»åŠ åˆ°ç³»ç»Ÿçš„ç¯å¢ƒå˜é‡è·¯å¾„ã€‚
        å½“æˆ‘ä»¬è¦æ·»åŠ è‡ªå·±çš„å¼•ç”¨æ¨¡å—æœç´¢ç›®å½•æ—¶ï¼Œå¯ä»¥é€šè¿‡åˆ—è¡¨ list çš„ append()æ–¹æ³•ï¼›
        sys.path.append() # ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„å‡å¯
        æ³¨1ï¼šè¿™ç§æ–¹æ³•æ˜¯è¿è¡Œæ—¶ä¿®æ”¹ï¼Œè„šæœ¬è¿è¡Œåå°±ä¼šå¤±æ•ˆã€‚
        æ³¨2ï¼šç³»ç»Ÿç¯å¢ƒåªèƒ½æ˜¯ç›®å½•ï¼Œä¸èƒ½æ˜¯æ–‡ä»¶ã€‚
        æ³¨3ï¼šå¦‚æœéœ€è¦è‡ªå®šä¹‰æœç´¢ä¼˜å…ˆçº§ï¼Œå¯ä»¥ä½¿ç”¨å¦‚sys.path.insert(1, "./model")ã€‚

        from pprint import pprint
        pprint(sys.path) # åœ¨è¿™é‡Œï¼Œpprintæ¨¡å—åªæ˜¯ç”¨æ¥ä½¿äº‹æƒ…çœ‹èµ·æ¥æ¼‚äº®
      </pre>

      <li>RNN dataloader</li>
      <pre>
        RNN/LSTMå…³äºä¸åŒé•¿çŸ­è§†é¢‘çš„å¯¹é½ï¼Œæœ‰å†…ç½®çš„padæ–¹å¼ï¼š
        >>> x1 = torch.randn(90, 73)
        >>> x2 = torch.randn(90, 73)
        >>> x3 = torch.randn(87, 73)
        >>> x4 = torch.randn(92, 73)
        >>> y = [x1, x2, x3, x4]
        >>> import torch.nn.utils.rnn as rnn_utils
        >>> y = rnn_utils.pad_sequence(y, batch_first=True)
        >>> æˆä¸º[4, 92, 73]å½¢çŠ¶çš„å¼ é‡
      </pre>

      <li>å›¾åƒå¤„ç†åº“æ•ˆæœä¸ä½³</li>
      <pre>
        https://github.com/assafshocher/ResizeRight
        å‚è€ƒ<a href="https://twitter.com/jaakkolehtinen/status/1258102168176951299">æ¨æ–‡</a>çš„ä¸€å¥è¯ï¼š
        Yeah, my advice to all my students is to never trust any image processing these libraries do. And always, ALWAYS verify visually that you get expected behavior, no matter how â€œtrivialâ€ the operation
      </pre>

      <li>æ˜¾å­˜ç¢ç‰‡åŒ–å¯¼è‡´CUDA OOM</li>
      <pre>
        ãƒ»ç°è±¡ç‰¹å¾ï¼š
            reserved >> allocated ä¸” reserved - allocated > try to allocateï¼Œä½†æŠ¥OOM

        ãƒ»æœºåˆ¶ç†è§£ï¼š
            CUDA é©±åŠ¨ åªçŸ¥é“ä¸¤ç±»æ˜¾å­˜ï¼š
            usedï¼ˆå·²è¢«æŸäº›ç¨‹åºå ç”¨ï¼‰
            freeï¼ˆå®Œå…¨ç©ºé—²ï¼‰
            PyTorch caching allocator åœ¨ CUDA ä¸Šç”³è¯·å¤§å—æ˜¾å­˜ä»¥åï¼Œä¼šè‡ªå·±åšäºŒæ¬¡ç®¡ç†ã€‚
            éƒ¨åˆ†è¢«å¼ é‡å®é™…ç”¨æ‰ â†’ allocated
            éƒ¨åˆ†æš‚æ—¶é—²ç½®ï¼Œä½† PyTorch ç¼“å­˜ç€å‡†å¤‡ä»¥åå¤ç”¨ï¼ˆå¥½å¤„æ˜¯å‡å°‘é¢‘ç¹ malloc/freeï¼‰ â†’ reserved - allocated
            ğŸ‘‰ å¦‚æœ reserved â‰« allocatedï¼Œè¯´æ˜ PyTorch æŠ¢äº†å¾ˆå¤šæ˜¾å­˜ï¼Œä½†æ²¡ç”¨å®Œï¼Œå¤§éƒ¨åˆ†åœ¨ç¼“å­˜æ± é‡Œâ€œç¢ç‰‡åŒ–â€ã€‚é€ æˆfree poolå¤ªå°äº†ï¼Œreserved poolåˆå¤ªç¢ç‰‡åŒ–ï¼Œå¤§å—å†…å­˜ç”³è¯·ä¸ä¸‹æ¥ã€‚


        ãƒ»é€ æˆç»“æœï¼š
            è™½ç„¶try to allocateçš„æ˜¾å­˜å¾ˆå°ï¼Œ
            ä¸€æ–¹é¢ reserved - allocatedï¼Œè™½ç„¶å¤§ï¼Œä½†æ˜¯ç¢ç‰‡åŒ–ä¸¥é‡ï¼Œå¯¼è‡´æ‹¿ä¸å‡ºä¸€æ•´å—å¤§äºtry to allocateçš„blockã€‚
            å¦ä¸€æ–¹é¢ï¼Œfree < try to allocateï¼Œå› ä¸ºé™¤äº†PyTorch reservedï¼ŒNCCL/cudnn/cublas context + workspaceä¹Ÿä¼šå ç”¨å¾ˆå¤šæ˜¾å­˜ã€‚
            å¯ä»¥è§‚å¯Ÿï¼Œè®­ç»ƒç¨‹åºåˆšå¯åŠ¨ï¼Œå°±ç›´æ¥åƒæ‰çš„æ˜¾å­˜ï¼Œé‚£å°±æ˜¯ NCCL/cudnn/cublas context + workspaceã€‚å¦‚æœè¿è¡Œè¿‡ç¨‹ä¸­æ…¢æ…¢æ¶¨ä¸Šå»ï¼Œé‚£å°±æ˜¯ç¼“å­˜/ç¢ç‰‡ã€‚

        ãƒ»è§£å†³æ–¹æ¡ˆï¼š
            å¯ä»¥è®¾ç½®max_split_size_mb < try to allocateï¼Œé™åˆ¶ç¼“å­˜æ± é‡Œæœ€å¤§å¯åˆ‡åˆ† block çš„å¤§å°ã€‚ä»¤æœ¬èº«æ¯”è¾ƒå¤§å—çš„ç©ºé—²blockèƒ½ä¿ç•™ä¸‹æ¥ï¼Œä¸è¢«éšæ„åˆ†å‰²ã€‚ï¼ˆPyTorchçš„é»˜è®¤ç­–ç•¥æ˜¯æ‰€æœ‰å¤§å°çš„ç©ºé—²Blockéƒ½å¯ä»¥è¢«åˆ†å‰²ï¼‰
            ä¹Ÿå¯æŒ‰ç»éªŒå€¼è®¾ç½®ï¼š256 ~ 512 MB é€šå¸¸è¶³å¤Ÿ

        ãƒ»å…·ä½“ç”¨æ³•ï¼š
            æ–¹å¼ä¸€ï¼šexport PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
            æ–¹å¼äºŒï¼š
            # åœ¨ import torch ä¹‹å‰è®¾ç½®
            os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:512"
      </pre>

      <li>è£…é¥°å™¨</li>
      <pre>
        æ³¨å†Œå™¨çš„é¢„å¤‡çŸ¥è¯† â€”â€”â€”â€” è£…é¥°å™¨
        ä»£ç è¿è¡ŒæœŸé—´åŠ¨æ€å¢åŠ åŠŸèƒ½çš„æ–¹å¼ï¼Œç§°ä¹‹ä¸ºâ€œè£…é¥°å™¨â€ï¼ˆDecoratorï¼‰

        <font color="brown">ä¸ºä»€ä¹ˆè¦ä½¿ç”¨è£…é¥°å™¨</font>
        å‡å¦‚ç°æœ‰ä¸€ä¸ªæ±‚å’Œå‡½æ•°addï¼Œ
        def add(a, b):
	        print(a + b)
        ç°åœ¨è¦æ±‚ç»Ÿè®¡å‡½æ•°æ‰§è¡Œçš„æ—¶é•¿ã€‚
      </pre>
      <pre>
        æ–¹å¼1ï¼šå¯¹åŸå‡½æ•°åšä¿®æ”¹ã€‚
        def add(a, b):
            start = time.time()
            print(a + b)
            time.sleep(2) # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
            long = time.time() - start
            print(f'å…±è€—æ—¶{long}ç§’ã€‚')
        æ–¹å¼1ç¼ºç‚¹ï¼šä¸ä»…å¢åŠ äº†è€¦åˆæ€§ï¼Œæ‰©å±•å’Œå¤ç”¨ä¹Ÿå˜å¾—éš¾ä»¥å®ç°ã€‚å¦‚æœå†å¢åŠ ä¸€ä¸ªè®°å½•æ—¥å¿—çš„åŠŸèƒ½ä»¥åŠå¯¹ç¨‹åºä¸­æ‰€æœ‰çš„å‡½æ•°éƒ½è¿›è¡Œæ—¶é•¿ç»Ÿè®¡ï¼Œå·¥ä½œé‡å°†éå¸¸å¤§ï¼Œæƒ³æƒ³å°±ç‘Ÿç‘Ÿå‘æŠ–ã€‚
      </pre>
      <pre>
        æ–¹å¼2ï¼š
        def timer(func,*args):
            start = time.time()
            func(*args)
            time.sleep(2)#æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
            long = time.time() - start
            print(f'å…±è€—æ—¶{long}ç§’ã€‚')

        timer(add,1,2)
        æ–¹å¼2ç¼ºç‚¹ï¼šæ²¡æœ‰æ”¹å˜åŸå‡½æ•°ï¼Œä½†æ˜¯æ”¹å˜äº†å‡½æ•°è°ƒç”¨æ–¹å¼ï¼Œæ¯ä¸ªè°ƒç”¨addçš„åœ°æ–¹éƒ½éœ€è¦ä¿®æ”¹ã€‚
      </pre>
      <pre>
        æ–¹å¼3ï¼š
        ä½¿ç”¨è£…é¥°å™¨ï¼šæ—¢ä¸ç”¨ä¿®æ”¹åŸå‡½æ•°ï¼Œåˆä¸ç”¨æ”¹å˜è°ƒç”¨æ–¹å¼ï¼Œè£…é¥°å™¨é—ªäº®ç™»åœºã€‚
        @timer è£…é¥°å™¨ä¿®é¥°å‡½æ•° add ()ï¼š
        def timer(func):
            def wrapper(*args, **kwargs):
                start = time.time()
                func(*args, **kwargs) # æ­¤å¤„æ‹¿åˆ°äº†è¢«è£…é¥°çš„å‡½æ•°func
                time.sleep(2)# æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
                long = time.time() - start
                print(f'å…±è€—æ—¶{long}ç§’ã€‚')
            return wrapper # è¿”å›å†…å±‚å‡½æ•°çš„å¼•ç”¨

        @timer
        def add(a, b):
            print(a+b)

        add(1, 2) # æ­£å¸¸è°ƒç”¨add
        æŠŠ@timeræ”¾åˆ°add()å‡½æ•°çš„å®šä¹‰å¤„ï¼Œç›¸å½“äºæ‰§è¡Œäº†è¯­å¥ï¼šadd = timer(add)
      </pre>
      <pre>
        <font color="brown">ä»€ä¹ˆæ˜¯è£…é¥°å™¨</font>
        é¦–å…ˆæ¥çœ‹å‡ ä¸ªæ¦‚å¿µï¼š
        é«˜é˜¶å‡½æ•°ï¼ˆåµŒå¥—å‡½æ•°ï¼‰ï¼šæ¥å—å‡½æ•°ä¸ºå…¥å‚ï¼Œæˆ–è€…æŠŠå‡½æ•°ä½œä¸ºç»“æœè¿”å›çš„å‡½æ•°ã€‚
        é—­åŒ…ï¼šæŒ‡å»¶ä¼¸äº†ä½œç”¨åŸŸçš„å‡½æ•°ï¼Œå…¶ä¸­åŒ…å«å‡½æ•°å®šä¹‰ä½“ä¸­å¼•ç”¨ã€ä½†æ˜¯ä¸åœ¨å®šä¹‰ä½“ä¸­å®šä¹‰çš„éå…¨å±€å˜é‡ã€‚ç®€å•æ¥è¯´å°±æ˜¯åµŒå¥—å‡½æ•°å¼•ç”¨äº†å¤–å±‚å‡½æ•°çš„å˜é‡ã€‚

        è£…é¥°å™¨æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªè¿”å›å‡½æ•°çš„é«˜é˜¶å‡½æ•°ï¼Œå®ƒå¯ä»¥è®©å…¶å®ƒå‡½æ•°åœ¨ä¸ç»è¿‡ä¿®æ”¹çš„æƒ…å†µä¸‹å¢åŠ ä¸€äº›åŠŸèƒ½ã€‚è¿™ä¹Ÿå°±æ˜¯è£…é¥°çš„æ„ä¹‰ï¼Œè¿™ç§è£…é¥°æœ¬èº«ä»£è¡¨ç€ä¸€ç§åŠŸèƒ½ï¼Œå¦‚æœç”¨å®ƒä¿®é¥°ä¸åŒçš„å‡½æ•°ï¼Œé‚£ä¹ˆä¹Ÿå°±æ˜¯ä¸ºè¿™äº›å‡½æ•°å¢åŠ è¿™ç§åŠŸèƒ½ã€‚
        ä¸€èˆ¬è€Œè¨€ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è£…é¥°å™¨æä¾›çš„ @ è¯­æ³•ç³–ï¼ˆSyntactic Sugarï¼‰æ¥ä¿®é¥°å…¶å®ƒå‡½æ•°æˆ–å¯¹è±¡ã€‚
      </pre>
      <pre>
        è£…é¥°å™¨çš„åŠ è½½åˆ°æ‰§è¡Œçš„æµç¨‹ï¼š
        æ¨¡å—åŠ è½½ ->> é‡åˆ°@ï¼Œæ‰§è¡Œtimerå‡½æ•°ï¼Œä¼ å…¥addå‡½æ•° ->> ç”Ÿæˆtimer..wrapperå‡½æ•°å¹¶å‘½åä¸ºaddï¼Œå…¶å®æ˜¯è¦†ç›–äº†åŸåŒåå‡½æ•° ->> è°ƒç”¨add(1, 2) ->> å»æ‰§è¡Œtimer..wrapper(1, 2) ->> wrapperå†…éƒ¨æŒæœ‰åŸaddå‡½æ•°å¼•ç”¨(func)ï¼Œè°ƒç”¨func(1, 2) ->>ç»§ç»­æ‰§è¡Œå®Œwrapperå‡½æ•°
      </pre>
      <pre>
        <font color="seablue">å…¶å®ƒé—®é¢˜</font>
        - å­˜åœ¨å¤šä¸ªè£…é¥°å™¨ï¼Œæ‰§è¡Œé¡ºåºæ˜¯ä»€ä¹ˆæ ·
        - æ€ä¹ˆå†™ä¸€ä¸ªå¸¦å‚æ•°çš„è£…é¥°å™¨
        - ç±»è£…é¥°å™¨ï¼Œä¸å¸¦å‚æ•°çš„ç±»è£…é¥°å™¨ï¼Ÿ
        - ç»è¿‡è£…é¥°å™¨ä¹‹åçš„å‡½æ•°è¿˜æ˜¯åŸæ¥çš„å‡½æ•°å—ï¼Ÿå¦‚ä½•ä¼ªè£…æˆåŸå‡½æ•°ï¼Œæ‹¥æœ‰åŸå‡½æ•°çš„å±æ€§
        å‚è€ƒé“¾æ¥ï¼šhttps://blog.csdn.net/u011331397/article/details/113481370
      </pre>

      <li>æ³¨å†Œå™¨</li>
      æ³¨å†Œå™¨ç®¡ç†å…±äº«ç›¸ä¼¼åŠŸèƒ½çš„ä¸åŒæ¨¡å—ï¼Œ æ¯”å¦‚è¯´ç›®æ ‡æ£€æµ‹ä¸­çš„backbones, head, and necksï¼Œè®¸å¤šæ·±åº¦å­¦ä¹ çš„å·¥ç¨‹ä½¿ç”¨æ³¨å†Œç®¡ç†æ•°æ®é›†å’Œæ¨¡å‹æ¨¡å—ã€‚
      <pre>
        ä»€ä¹ˆæ˜¯æ³¨å†Œï¼š
        æ³¨å†Œå™¨å¯ä»¥çœ‹ä½œæ˜¯å®Œæˆäº†stringç±»å‹->ç±»åï¼ˆå¦‚æ¨¡å‹åç§°->æ¨¡å‹ç±»ï¼‰çš„ä¸€ä¸ªæ˜ å°„ã€‚å•ä¸ªæ³¨å†Œå™¨åŒ…å«çš„è¿™äº›ç±»é€šå¸¸å…·æœ‰ç›¸ä¼¼çš„APIï¼Œä½†æ˜¯å®ç°ä¸åŒçš„ç®—æ³•ã€‚æ¯”å¦‚è¯´ç›®æ ‡æ£€æµ‹ä¸­çš„ä¸»å¹²ç½‘ç»œã€‚
      </pre>
      å®ç°æ–¹å¼ï¼š
      <pre>
      è¦æ³¨å†Œçš„æ¨¡å—
      models/model.py:
      class Model:
          pass

      @Registers.model.register
      class Model1(Model):
          pass


      @Registers.model.register
      class Model2(Model):
          pass


      @Registers.model.register
      class Model3(Model):
          pass
      </pre>
      <pre>
      æ³¨å†Œå™¨ Register
      class Register:

      def __init__(self, registry_name):
          self._dict = {}
          self._name = registry_name

      def __setitem__(self, key, value):
          if not callable(value):
              raise Exception(f"Value of a Registry must be a callable!\nValue: {value}")
          if key is None:
              key = value.__name__
          if key in self._dict:
              logging.warning("Key %s already in registry %s." % (key, self._name))
          self._dict[key] = value

      def register(self, target):
          """Decorator to register a function or class."""

          def add(key, value):
              self[key] = value
              return value

          if callable(target):
              # @reg.register
              return add(None, target)
          # @reg.register('alias')
          return lambda x: add(target, x)

      def __getitem__(self, key):
          return self._dict[key]

      def __contains__(self, key):
          return key in self._dict

      def keys(self):
          """key"""
          return self._dict.keys()
      </pre>
      <pre>
        è¡¥å……ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼Œ<font color="blue">@æ˜¯pythonçš„è£…é¥°å™¨è¯­æ³•ç³–</font>ã€‚
        @decorate
        def func():
        ç­‰ä»·äº
        func = decorate(func)
      </pre>
      <pre>
        å…³é”®æ˜¯registerå‡½æ•°ï¼Œå®ƒå¯ä»¥ä½œä¸ºè£…é¥°å™¨ï¼Œæ³¨å†Œä¸€ä¸ªå‡½æ•°æˆ–è€…ä¸€ä¸ªç±»ã€‚ä¾‹å¦‚ï¼š
        @register_obj.register("model_one")
        class Model1:
        æœ€ç»ˆæ‰§è¡Œçš„æ˜¯add("model_one", Model_1)ã€‚å‚è€ƒ<a href="https://applenob.github.io/python/register/">link</a>
      </pre>
      æ³¨å†Œå™¨ä½¿ç”¨å®ä¾‹ï¼šæˆ‘ä»¬å®šä¹‰ä¸€äº›ç®€å•çš„å‡½æ•°ï¼Œä¾‹å¦‚åŠ å‡ä¹˜é™¤ç­‰å‡½æ•°ï¼Œä¸ºäº†çœç•¥é‡å¤ä»£ç ï¼Œæˆ‘ä»¬å°±ç›´æ¥ç»™ä»–ä»¬ç”¨Registeræ³¨å†Œäº†ã€‚
      <pre>
        1. æ³¨å†ŒRegisterã€‚
        Register_func = Register("Register_func")

        @Register_func.register
        def add(x,y):
            return x+y

        @Register_func.register
        def minus(x,y):
            return x-y
        '''
        è¿™é‡Œregisterå‡½æ•°æ˜¯ä¸€ä¸ªè£…é¥°å™¨ï¼Œç›¸å½“äºæ³¨å†Œäº†{minus.__name__:minus}åˆ°å­—å…¸é‡Œã€‚
        '''

        @Register_func.register
        def multi(x,y):
            return x*y

        @Register_func.register
        def div(x,y):
            return x/y
        2. ä½¿ç”¨æ³¨å†Œæ¨¡å—ã€‚
        operation = Register_func["add"]
        result = operation(1,2)
        print(result)
      </pre>

      <li>lambdaè¡¨è¾¾å¼</li>
      lambdaè¡¨è¾¾å¼ä¹Ÿç§°åŒ¿åå‡½æ•°æˆ–å•è¡¨è¾¾å¼å‡½æ•°ã€‚
      <pre>
        å‡½æ•°å¼ç¼–ç¨‹ï¼ˆFunctional Programmingï¼‰æºè‡ªäºæ•°å­¦ç†è®ºï¼Œå®ƒä¼¼ä¹ä¹Ÿæ›´é€‚ç”¨äºæ•°å­¦è®¡ç®—ç›¸å…³çš„åœºæ™¯ã€‚
        å¾ˆå¤šäººéƒ½åœ¨è°ˆè®ºå‡½æ•°å¼ç¼–ç¨‹ï¼Œåªæ˜¯å¾ˆå¤šäººç«™åœ¨ä¸åŒçš„è§’åº¦çœ‹åˆ°çš„æ˜¯å®Œå…¨ä¸ä¸€æ ·çš„é£æ™¯ã€‚åšæŒå®ç”¨ä¸»ä¹‰çš„ Python è€å¸æœºä»¬å¯¹å¾… FP çš„æ€åº¦åº”è¯¥æ›´åŠ åŒ…å®¹ï¼Œè™½ç„¶ä»–ä»¬ä¸ç›¸ä¿¡é“¶å¼¹ï¼Œä½†å†¥å†¥ä¸­ä¼¼ä¹èƒ½æ„Ÿè§‰åˆ° FP æš—åˆäº† Python æ•™ä¹‰ï¼ˆThe Zen of Pythonï¼‰çš„æŸäº›æ€æƒ³ï¼Œè€Œä¸”æ—¢ç„¶ Python æ˜¯ä¸€é—¨å¤šèŒƒå¼ç¼–ç¨‹è¯­è¨€ï¼Œå¹¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ”¯æŒå‡½æ•°å¼ç¼–ç¨‹ï¼Œé‚£å°±æ›´æ²¡æœ‰ç†ç”±æ‹’ç»å®ƒã€‚
      </pre>
      <pre>
        map()ï¼šå°†åºåˆ—ä¸­çš„å…ƒç´ é€šè¿‡å¤„ç†å‡½æ•°å¤„ç†åè¿”å›ä¸€ä¸ªæ–°çš„åˆ—è¡¨
        filter()ï¼šå°†åºåˆ—ä¸­çš„å…ƒç´ é€šè¿‡å‡½æ•°è¿‡æ»¤åè¿”å›ä¸€ä¸ªæ–°çš„åˆ—è¡¨
        reduce()ï¼šå°†åºåˆ—ä¸­çš„å…ƒç´ é€šè¿‡ä¸€ä¸ªäºŒå…ƒå‡½æ•°å¤„ç†è¿”å›ä¸€ä¸ªç»“æœ

        filter/reduce/mapç­‰åŸºæœ¬çš„å†…ç½®æ•°æ®å¤„ç†å‡½æ•°ï¼Œéœ€è¦ä¸¤ä¸ªå‚æ•°,ç¬¬ä¸€ä¸ªæ˜¯ä¸€ä¸ªå¤„ç†å‡½æ•°,ç¬¬äºŒä¸ªæ˜¯ä¸€ä¸ªåºåˆ—(list,tuple,dict)ã€‚
      </pre>
      <pre>
        lambdaæ˜¯Pythonæ”¯æŒä¸€ç§æœ‰è¶£çš„è¯­æ³•ï¼Œå®ƒå…è®¸ä½ å¿«é€Ÿå®šä¹‰å•è¡Œçš„æœ€å°å‡½æ•°ï¼Œç±»ä¼¼ä¸Cè¯­è¨€ä¸­çš„å®ã€‚
        ç»“åˆå†…ç½®å‡½æ•°ï¼Œå¯ä»¥æ—¢é«˜æ•ˆåˆç®€æ´ï¼š
        li = [1, 2, 3, 4, 5]
        # åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ åŠ 1
        map(lambda x: x+1, li) # [2,3,4,5,6]

        # è¿”å›åºåˆ—ä¸­çš„å¶æ•°
        filter(lambda x: x % 2 == 0, li) # [2, 4]

        # è¿”å›æ‰€æœ‰å…ƒç´ ç›¸ä¹˜çš„ç»“æœ
        reduce(lambda x, y: x * y, li) # 1*2*3*4*5 = 120
      </pre>



  </ul>






<!-- åŠ è½½å‡ºè¯„è®ºï¼Œæ˜¯ä½¿ç”¨Disqusçš„è®ºå›çŸ­åï¼ˆshortnameï¼‰
A shortname is the unique identifier assigned to a Disqus site.

https://segmentfault.com/a/1190000005773009
https://help.disqus.com/en/articles/1717111-what-s-a-shortname
https://blog.csdn.net/weixin_34327761/article/details/89630337
   -->

<div id="disqus_thread"></div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../comments/inlineDisqussions.js"></script>
<script src="../../js/disqus.js"></script>

                        </div>
                        <div class="col-md-4"></div>
                    </div>
                </div>
            </div>


            <div id="footer">
                <div class="container">
                    Built by <a href="https://github.com/oinkina">Oinkina</a> with
                    <a href="http://jaspervdj.be/hakyll">Hakyll</a>
                    using <a href="http://getbootstrap.com/">Bootstrap</a>,
                    <a href="http://www.mathjax.org/">MathJax</a>,
                    <a href="http://disqus.com/">Disqus</a>,
                    <a href="https://github.com/unconed/MathBox.js">MathBox.js</a>,
                    <a href="http://highlightjs.org/">Highlight.js</a>,
                    and <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>.
                </div>
            </div>
        </div>

    <!-- jQuery-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

    <script src="../../bootstrap/js/bootstrap.min.js"></script>

    <script src="../../highlight/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <script src="../../js/footnotes.js"></script>

    <script src="../../comments/inlineDisqussions.js"></script>

    <noscript>Enable JavaScript for footnotes, Disqus comments, and other cool stuff.</noscript>

    </body>

</html>
