## 带注解的Transformer

[TOC]

**by** <font color="brown">**harvardnlp**</font>

#### 前言

“Attention is All You Need”论文本身写得很清晰，但是传统的观点认为，正确实现它相当困难。所以这里一行行讲解、实现一个PyTorch版的Transformer。

